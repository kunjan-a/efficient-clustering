
	
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<meta http-equiv="X-UA-Compatible" content="IE=7" />
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="author" content="iParadigms, LLC" />
    <meta name="keywords" content="" /> 
    <meta name="description" content="" />
    <meta name="viewport" content="width = initial-scale" />
    <meta name="viewport" content="height = initial-scale" />
    
<title>Turnitin Originality Report</title>

<base href="http://www.turnitin.com">
<style type="text/css">
	
body	{
	color: #000;
	background: #ddd;
	padding: 0;
	border: 0;
	font: 14px Arial, Verdana, sans-serif;
	margin: 0;
	text-align: center;
	}
	
form	{
	padding: 0;
	margin: 0;
	}
	
p	{
	padding: .8em 1.5em;
	margin: 0;
	text-align: left;
	}
	
img	{
	border: 0;
	padding: 0;
	}

div	{
	padding: 0;
	border: 0;
	text-align: left;
	}
	
strong	{
	font-weight: bold;
	}
	
h2	{
	font-size: 15px;
	margin: 20px 0 10px 20px;
	}
	
a:link, a:visited	{
	text-decoration: underline;
	color: #00f;
	}
	
a:hover, a:active	{
	text-decoration: underline;
	color: #888;
	}
	
img#logo	{
	float: right;
	padding-right: 20px;
	padding-top: 10px;
	}
	
div#container	{
	border: 1px solid #aaa;
	width: 770px;
	margin: 20px auto;
	background: #fff;
	padding: 10px 0;
	}
	
div#top	{
	background: #fff;
	width: 7in;
	margin: auto;
	padding-bottom: 15px;
	}
	
div#content	{
	background: #fff;
	}
	
#top p	{
	padding: .3em 0 .3em 20px;
	}

#top span	{
	padding-right: 35px;
	}
	
#top p#orig	{
	padding-top: 15px;
	}
	
#orig span#score.red	{
	border-right: 18px solid red;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.orange	{
	border-right: 18px solid orange;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.yellow	{
	border-right: 18px solid yellow;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.green	{
	border-right: 18px solid green;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.blue	{
	border-right: 18px solid blue;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
div.divider	{
	width: 7in;
	border: 1px dotted #888;
	margin: auto;
	padding: 4px 0 4px 10px;
	font-weight: bold;
	background: #ddd;
	font-size: 15px;
	}
	
div.links	{
	width: 7in;
	margin: auto;
	}
	
.links div	{
	padding: 15px 20px 15px 20px;
	border-bottom: 1px dotted #888;
	}
	
.links div#last	{
	padding: 15px 20px 20px 20px;
	border-bottom: 0;
	}
	
div.number	{
	float: right;
	background: white;
	border: 1px solid #888;
	margin: 0 0 0 20px;
	padding: .1em .5em;
	text-align: center;
	color: black;
	font-weight: bold;
	font-size: 15px;
	line-height: 20px;
	}
	
div.number-l	{
	float: left;
	background: white;
	border: 1px solid #888;
	margin: 6px 16px 10px 0;
	padding: .1em .5em;
	text-align: center;
	color: black;
	font-weight: bold;
	font-size: 15px;
	line-height: 20px;
	}
	
.links div p	{
	padding: .2em 1.5em .4em 0;
	}
	
.links div p#mess	{
	padding: .2em 1.5em 0 0;
	}
	
div#body	{
	line-height: 1.5em;
	width: 7in;
	margin: auto;
	padding-bottom: 20px;
	}
	
#body p	{
	color: #555;
	padding-top: 30px;
	line-height: 20px;
	}

	
#body a	{
	display: block;
	color: red;
	margin: 1em 3em;
	background-repeat: no-repeat;
	background-position: top right;
	padding: 1em 1em;
	border: 1px dotted #888;
	font-weight: bold;
	font-size: 15px;
	text-decoration: none;
	line-height: 26px;
	background: #FFFFE5;
	}

#body span	{
	color: #555;
	font-weight: normal;
	font-size: 14px;
	}

#body span.number	{
	display: block;
	float: right;
	color: #000;
	font-weight: normal;
	border: 1px solid #888;
	padding: 0 6px;
	font-weight: bold;
	margin-left: 15px;
	font-size: .9em;
	background: #fff;
	}
	
#actions	{
	display: none;
	}
</style>

<!--[if !IE]>-->
<link href="https://ne.edgecastcdn.net/800404/www.turnitin.com/css/cms/page_type/blackbox_or.css"  media="only screen and (max-device-width: 480px)"  rel="stylesheet" type="text/css" /> 
<!--<![endif]-->

</head>

<body id="or_print_report">


<div id="container">

<div id="top">
    <div id="content">
        <!-- ######### Top Body  ##########################--> 
        <div id="top_body">
            <p id="title">
            <img src="/images/turnitin_logo.gif" id="logo" width="60">
            Turnitin Originality Report
            </p>
                <div class="general_info">
                    <p>
                        <span>K Means Implementation on GGPU</span>
                        
                        by Kunjan Agarwal
                        
                    </p>
                    <p>
                        From CS699 MTech Thesis (Thesis (CS699,CS799))
                    </p>
                    <ul>
                        <li>Processed on 02-Mar-2013 16:37 IST</li>
                        <li>ID: 308774027</li>
                        <li>Word Count: 12462</li>
                    </ul>
                </div>
                <div class="similarity_box">
                    <div class="overall_similarity">
                        <div class="color_box green">&nbsp;</div>
                        <div class="similarity_title">Similarity Index</div>
                        <div class="similarity_percent">12%</div>
                    </div>
                    <div class="similarity_by_source">
                        <div class="similarity_title">Similarity by Source</div>
                        <dl>
                            <dt>Internet&nbsp;Sources:</dt>
                            <dd>8%</dd>
                            <div class="clear"></div>
                            <dt>Publications:</dt>
                            <dd>10%</dd>
                            <div class="clear"></div>
                            <dt>Student&nbsp;Papers:</dt>
                            <dd>6%</dd>
                            <div class="clear"></div>
                        </dl>
                    </div>
                </div>
                <div class="clear"></div>
                                 
        </div>
        <!-- ######### END Top Body  ##########################--> 
    </div>
</div>

<div class="divider">sources:</div>

<div class="links">

	<div>
	<div class="number-l">1</div>
	<p>1% match (publications)</p>

	<a style="color:red" href="http://dx.doi.org/10.1109/MM.2008.31">Erik Lindholm. "NVIDIA Tesla: A Unified Graphics and Computing Architecture", IEEE Micro, 03/2008</a>

	</div>
	<div>
	<div class="number-l">2</div>
	<p>1% match (publications)</p>

	<a style="color:green" href="http://dx.doi.org/10.1109/CIT.2010.60">You Li. "Speeding up K-Means Algorithm by GPUs", 2010 10th IEEE International Conference on Computer and Information Technology, 06/2010</a>

	</div>
	<div>
	<div class="number-l">3</div>
	<p>< 1% match (Internet from 19-Apr-2009)</p>

	<a style="color:blue" href="http://biometrics.cse.msu.edu/JainDataClusteringPRL09.pdf">http://biometrics.cse.msu.edu/JainDataClusteringPRL09.pdf</a>

	</div>
	<div>
	<div class="number-l">4</div>
	<p>< 1% match (Internet from 04-May-2009)</p>

	<a style="color:brown" href="http://developer.download.nvidia.com/compute/cuda/2_0/docs/NVIDIA_CUDA_Programming_Guide_2.0.pdf">http://developer.download.nvidia.com/compute/cuda/2_0/docs/NVIDIA_CUDA_Programming_Guide_2.0.pdf</a>

	</div>
	<div>
	<div class="number-l">5</div>
	<p>< 1% match (publications)</p>

	<a style="color:#ff6600" href="http://dx.doi.org/10.1109/HiPC.2011.6152713">Mohiuddin K. Wasif. "Scalable clustering using multiple GPUs", 2011 18th International Conference on High Performance Computing, 12/2011</a>

	</div>
	<div>
	<div class="number-l">6</div>
	<p>< 1% match (publications)</p>

	<a style="color:#630000" href="http://dx.doi.org/10.1109/CLUSTERWKSP.2010.5613079">Karantasis, Konstantinos I., Eleftherios D. Polychronopoulos, and George N. Dimitrakopoulos. "Accelerating data clustering on GPU-based clusters under shared memory abstraction", 2010 IEEE International Conference On Cluster Computing Workshops and Posters (CLUSTER WORKSHOPS), 2010.</a>

	</div>
	<div>
	<div class="number-l">7</div>
	<p>< 1% match (Internet from 04-May-2009)</p>

	<a style="color:#009cff" href="http://www.cse.iitd.ernet.in/esproject/homepage/docs/projects/2005-2006/final/AfuSreenivasa.pdf">http://www.cse.iitd.ernet.in/esproject/homepage/docs/projects/2005-2006/final/AfuSreenivasa.pdf</a>

	</div>
	<div>
	<div class="number-l">8</div>
	<p>< 1% match (publications)</p>

	<a style="color:#31ff00" href="http://dx.doi.org/10.1109/JCSSE.2012.6261977">Kijsipongse, Ekasit, and Suriya U-ruekolan. "Dynamic load balancing on GPU clusters for large-scale K-Means clustering", 2012 Ninth International Conference on Computer Science and Software Engineering (JCSSE), 2012.</a>

	</div>
	<div>
	<div class="number-l">9</div>
	<p>< 1% match (publications)</p>

	<a style="color:#330099" href="http://dx.doi.org/10.1109/SBAC-PAD.2011.10">Mouad Bahi. "High Performance by Exploiting Information Locality through Reverse Computing", 2011 23rd International Symposium on Computer Architecture and High Performance Computing, 10/2011</a>

	</div>
	<div>
	<div class="number-l">10</div>
	<p>< 1% match (Internet from 28-Jun-2010)</p>

	<a style="color:#00cc99" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnYzl2cW5jBF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZANmSjFHSVVnZUF1M2wzenZoZERablhhTjBKbS5UVGt3by5oTUFBVlk4/SIG=1179k5f0r/**http%3A//www.cs.virginia.edu/~sc5nf/">http://www.cs.virginia.edu/~sc5nf/</a>

	</div>
	<div>
	<div class="number-l">11</div>
	<p>< 1% match (publications)</p>

	<a style="color:#ff0063" href="http://dx.doi.org/10.1109/ICPADS.2012.18">Misra, Prabhakar, and Mainak Chaudhuri. "Performance Evaluation of Concurrent Lock-free Data Structures on GPUs", 2012 IEEE 18th International Conference on Parallel and Distributed Systems, 2012.</a>

	</div>
	<div>
	<div class="number-l">12</div>
	<p>< 1% match (publications)</p>

	<a style="color:#006331" href="http://search.ebscohost.com/login.asp?r=13.9568054433109&svr=1&lang=en_us&x?direct=true&db=ECD&AN=74621094&site=ehost-live&EPSource=esi">Mirajkar, Gayatri. "Optimal Feature Selection using Independent Component Analysis and Significant Feature Processing Applied to Human Brain MR Images", Advances in Computational Sciences & Technology/09736107, 20111101</a>

	</div>
	<div>
	<div class="number-l">13</div>
	<p>< 1% match (Internet from 30-Oct-2009)</p>

	<a style="color:#9966ff" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnZDk3cTZoBF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZAMwc0FMLkVnZUF1MmFKYkdnTTJWN1lIMzMwRG1lOGtycndnY0FDSFNW/SIG=11er8h4jp/**http%3A//www.cs.rpi.edu/~civria/isaac08.pdf">http://www.cs.rpi.edu/~civria/isaac08.pdf</a>

	</div>
	<div>
	<div class="number-l">14</div>
	<p>< 1% match (Internet from 19-Sep-2010)</p>

	<a style="color:#9c6331" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnanQ5bWo1BF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZANqc3Y3ZzBnZUF1MmJfYWZJS2hqaC5TVVlKbS5UVGt5Vl9vQUFCUTV3/SIG=11oer37q1/**http%3A//www.ise.bgu.ac.il/faculty/liorr/hbchap15.pdf">http://www.ise.bgu.ac.il/faculty/liorr/hbchap15.pdf</a>

	</div>
	<div>
	<div class="number-l">15</div>
	<p>< 1% match (Internet from 15-Jun-2010)</p>

	<a style="color:#ce0031" href="http://lrd.yahooapis.com/_ylc=X3oDMTVncTVsbTE1BF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZANoYVVTakVnZUF1M09kNlhhUVBxX2pLaEFKbS5UVGt3WHVUQUFCWUxj/SIG=134t64nmj/**http%3A//www.cse.msu.edu/rgroups/biometrics/Publications/GeneralPRIP/JainDataClustering_PRL09.pdf">http://www.cse.msu.edu/rgroups/biometrics/Publications/GeneralPRIP/JainDataClustering_PRL09.pdf</a>

	</div>
	<div>
	<div class="number-l">16</div>
	<p>< 1% match (student papers from 22-Jul-2011)</p>

	<a style="color:#cc9900" href="/paperInfo.asp?r=13.9568054433109&svr=1&lang=en_us&oid=195145687&perc=0">Submitted to UT, Dallas on 2011-07-22</a>

	</div>
	<div>
	<div class="number-l">17</div>
	<p>< 1% match (Internet from 10-May-2011)</p>

	<a style="color:#63009c" href="http://www.security.iitk.ac.in/contents/publications/more/thesis_kayal.pdf">http://www.security.iitk.ac.in/contents/publications/more/thesis_kayal.pdf</a>

	</div>
	<div>
	<div class="number-l">18</div>
	<p>< 1% match (Internet from 31-Aug-2012)</p>

	<a style="color:#cc6600" href="http://www.hs.uni-hamburg.de/DE/Ins/Per/Abhranil/summer_report.pdf">http://www.hs.uni-hamburg.de/DE/Ins/Per/Abhranil/summer_report.pdf</a>

	</div>
	<div>
	<div class="number-l">19</div>
	<p>< 1% match (publications)</p>

	<a style="color:#cc0066" href="http://dx.doi.org/10.1016/j.jcp.2011.02.023">Cardoso, N.. "SU (2) lattice gauge theory simulations on Fermi GPUs", Journal of Computational Physics, 20110510</a>

	</div>
	<div>
	<div class="number-l">20</div>
	<p>< 1% match (Internet from 26-Oct-2010)</p>

	<a style="color:#33cc99" href="http://www.cs.virginia.edu/~skadron/Papers/bakkum_sqlite_gpgpu10.pdf">http://www.cs.virginia.edu/~skadron/Papers/bakkum_sqlite_gpgpu10.pdf</a>

	</div>
	<div>
	<div class="number-l">21</div>
	<p>< 1% match (publications)</p>

	<a style="color:#336699" href="http://dx.doi.org/10.1007/978-0-387-09823-4_14">Lior Rokach. "A survey of Clustering Algorithms", Data Mining and Knowledge Discovery Handbook, 2009</a>

	</div>
	<div>
	<div class="number-l">22</div>
	<p>< 1% match (publications)</p>

	<a style="color:red" href="http://dx.doi.org/10.1007/978-3-540-25966-4_14">Hanan Ayad. "A Probabilistic Model Using Information Theoretic Measures for Cluster Ensembles", Lecture Notes in Computer Science, 2004</a>

	</div>
	<div>
	<div class="number-l">23</div>
	<p>< 1% match (student papers from 21-May-2011)</p>

	<a style="color:green" href="/paperInfo.asp?r=13.9568054433109&svr=1&lang=en_us&oid=188342778&perc=0">Submitted to Associatie K.U.Leuven on 2011-05-21</a>

	</div>
	<div>
	<div class="number-l">24</div>
	<p>< 1% match (Internet from 30-May-2010)</p>

	<a style="color:blue" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnbWg2dXE4BF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZANJS0JLR0VnZUF1M3pvSy5YbTBjYUduMUlKbS5UVGt3Q1VHNEFCSXRx/SIG=1288f4ku4/**http%3A//bura.brunel.ac.uk/bitstream/2438/3975/1/Fulltext(Thesis).pdf">http://bura.brunel.ac.uk/bitstream/2438/3975/1/Fulltext(Thesis).pdf</a>

	</div>
	<div>
	<div class="number-l">25</div>
	<p>< 1% match (Internet from 06-Nov-2009)</p>

	<a style="color:brown" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnajkxNW92BF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZAN1RVNhaFVnZUF1Mk1nTEdYb2Rac3FJUlcwRG1lOGtyMGVHNEFDNTY0/SIG=11to8t147/**http%3A//www.cs.washington.edu/homes/syhahn/papers/tgp.pdf">http://www.cs.washington.edu/homes/syhahn/papers/tgp.pdf</a>

	</div>
	<div>
	<div class="number-l">26</div>
	<p>< 1% match (Internet from 04-Aug-2010)</p>

	<a style="color:#ff6600" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnczIybzhpBF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZANYeGhmT0VnZUF1MjVNcGFqeXlVWHNoWk1KbS5UVGt4Wmpta0FCZDUu/SIG=11v9t37b5/**http%3A//www.ces.clemson.edu/~stb/students/trupti_thesis.pdf">http://www.ces.clemson.edu/~stb/students/trupti_thesis.pdf</a>

	</div>
	<div>
	<div class="number-l">27</div>
	<p>< 1% match (publications)</p>

	<a style="color:#630000" href="http://dx.doi.org/10.1177/1094342012462751">Carpenter, I., R. Archibald, K. J. Evans, J. Larkin, P. Micikevicius, M. Norman, J. Rosinski, J. Schwarzmeier, and M. A. Taylor. "Progress towards accelerating HOMME on hybrid multi-core systems", International Journal of High Performance Computing Applications, 2012.</a>

	</div>
	<div>
	<div class="number-l">28</div>
	<p>< 1% match (student papers from 09-Oct-2012)</p>

	<a style="color:#009cff" href="/paperInfo.asp?r=13.9568054433109&svr=1&lang=en_us&oid=274072414&perc=0">Submitted to Middle East Technical University on 2012-10-09</a>

	</div>
	<div>
	<div class="number-l">29</div>
	<p>< 1% match (publications)</p>

	<a style="color:#31ff00" href="http://dx.doi.org/10.1007/978-3-642-02303-3_13">Eduard Ayguade. "A Proposal to Extend the OpenMP Tasking Model for Heterogeneous Architectures", Lecture Notes in Computer Science, 2009</a>

	</div>
	<div>
	<div class="number-l">30</div>
	<p>< 1% match (publications)</p>

	<a style="color:#330099" href="http://dx.doi.org/10.1155/2012/135926">Hussain, Hanaa M., Khaled Benkrid, Ali Ebrahim, Ahmet T. Erdogan, and Huseyin Seker. "Novel Dynamic Partial Reconfiguration Implementation of K-Means Clustering on FPGAs: Comparative Results with GPPs and GPUs", International Journal of Reconfigurable Computing, 2012.</a>

	</div>
	<div>
	<div class="number-l">31</div>
	<p>< 1% match (publications)</p>

	<a style="color:#00cc99" href="http://dx.doi.org/10.1109/IPDPS.2012.11">Anderson, Michael J., David Sheffield, and Kurt Keutzer. "A Predictive Model for Solving Small Linear Algebra Problems in GPU Registers", 2012 IEEE 26th International Parallel and Distributed Processing Symposium, 2012.</a>

	</div>
	<div>
	<div class="number-l">32</div>
	<p>< 1% match (student papers from 07-Oct-2010)</p>

	<a style="color:#ff0063" href="/paperInfo.asp?r=13.9568054433109&svr=1&lang=en_us&oid=151943805&perc=0">Submitted to University of Canterbury on 2010-10-07</a>

	</div>
	<div>
	<div class="number-l">33</div>
	<p>< 1% match (Internet from 11-Jan-2013)</p>

	<a style="color:#006331" href="http://books.openlibra.com/pdf/Programming-on-Parallel-Machines-OpenLibra.pdf">http://books.openlibra.com/pdf/Programming-on-Parallel-Machines-OpenLibra.pdf</a>

	</div>
	<div>
	<div class="number-l">34</div>
	<p>< 1% match (Internet from 22-Sep-2010)</p>

	<a style="color:#9966ff" href="http://lrd.yahooapis.com/_ylc=X3oDMTVndGxqajQyBF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZAN3aGRKRlVnZUF1M3ZlQXNuUzBsWUxndW5KbS5UVGt5YXNjTUFBd0RY/SIG=125et6omg/**http%3A//wwwx.cs.unc.edu/~tgamblin/pubs/scalable-cluster-ics10.pdf">http://wwwx.cs.unc.edu/~tgamblin/pubs/scalable-cluster-ics10.pdf</a>

	</div>
	<div>
	<div class="number-l">35</div>
	<p>< 1% match (publications)</p>

	<a style="color:#9c6331" href="">Abdu, Eman. "Clustering categorical data using data summaries and spectral techniques", Proquest, 20111108</a>

	</div>
	<div>
	<div class="number-l">36</div>
	<p>< 1% match (Internet from 29-Sep-2010)</p>

	<a style="color:#ce0031" href="http://www.cs.waikato.ac.nz/~abifet/MOA/StreamMining.pdf">http://www.cs.waikato.ac.nz/~abifet/MOA/StreamMining.pdf</a>

	</div>
	<div>
	<div class="number-l">37</div>
	<p>< 1% match (publications)</p>

	<a style="color:#cc9900" href="http://dx.doi.org/10.1109/CSE.2011.104">Fang, Jianbin, Ana Lucia Varbanescu, and Henk Sips. "An Auto-tuning Solution to Data Streams Clustering in OpenCL", 2011 14th IEEE International Conference on Computational Science and Engineering, 2011.</a>

	</div>
	<div>
	<div class="number-l">38</div>
	<p>< 1% match (Internet from 07-Dec-2012)</p>

	<a style="color:#63009c" href="http://sydneypcrepair.info/download/w7-32/ndis.sys">http://sydneypcrepair.info/download/w7-32/ndis.sys</a>

	</div>
	<div>
	<div class="number-l">39</div>
	<p>< 1% match (publications)</p>

	<a style="color:#cc6600" href="http://dx.doi.org/10.1109/ICTAI.2011.66">Manuel Yguel. "3D Mapping of Outdoor Environment Using Clustering Techniques", 2011 IEEE 23rd International Conference on Tools with Artificial Intelligence, 11/2011</a>

	</div>
	<div>
	<div class="number-l">40</div>
	<p>< 1% match (Internet from 13-Jun-2010)</p>

	<a style="color:#cc0066" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnaXZqaTRwBF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZAN6MWtaMEVnZUF1MzVHVk9uX21BZllPaHVKbS5UVGt3VnB2b0FEaXB5/SIG=12t3pgj1t/**http%3A//www.cse-web.iitkgp.ernet.in/~abhij/facad/03UG/Report/03CS3023_Sankalp_Agarwal.pdf">http://www.cse-web.iitkgp.ernet.in/~abhij/facad/03UG/Report/03CS3023_Sankalp_Agarwal.pdf</a>

	</div>
	<div>
	<div class="number-l">41</div>
	<p>< 1% match (Internet from 17-Sep-2012)</p>

	<a style="color:#33cc99" href="http://users.cecs.anu.edu.au/~williams/papers/P185.pdf">http://users.cecs.anu.edu.au/~williams/papers/P185.pdf</a>

	</div>
	<div>
	<div class="number-l">42</div>
	<p>< 1% match (Internet from 09-Sep-2012)</p>

	<a style="color:#336699" href="http://th6b.cn/th6b/archive/index.php/t-1046.html?s=">http://th6b.cn/th6b/archive/index.php/t-1046.html?s=</a>

	</div>
	<div>
	<div class="number-l">43</div>
	<p>< 1% match (publications)</p>

	<a style="color:red" href="http://dx.doi.org/10.1140/epjst/e2011-01398-x">T. Preis. "GPU-computing in econophysics and statistical physics", The European Physical Journal Special Topics, 03/2011</a>

	</div>
	<div>
	<div class="number-l">44</div>
	<p>< 1% match (Internet from 15-Jun-2011)</p>

	<a style="color:green" href="http://pca.narod.ru/WunschClustering.pdf">http://pca.narod.ru/WunschClustering.pdf</a>

	</div>
	<div>
	<div class="number-l">45</div>
	<p>< 1% match (Internet from 07-May-2003)</p>

	<a style="color:blue" href="http://shoshin.uwaterloo.ca/publications/pdfs/thesismas15.pdf">http://shoshin.uwaterloo.ca/publications/pdfs/thesismas15.pdf</a>

	</div>
	<div>
	<div class="number-l">46</div>
	<p>< 1% match (student papers from 12-Nov-2012)</p>

	<a style="color:brown" href="/paperInfo.asp?r=13.9568054433109&svr=1&lang=en_us&oid=283735806&perc=0">Submitted to Universiti Sains Malaysia on 2012-11-12</a>

	</div>
	<div>
	<div class="number-l">47</div>
	<p>< 1% match (Internet from 20-Dec-2012)</p>

	<a style="color:#ff6600" href="http://www.comp.hkbu.edu.hk/~chxw/papers/hpcc_2012.pdf">http://www.comp.hkbu.edu.hk/~chxw/papers/hpcc_2012.pdf</a>

	</div>
	<div>
	<div class="number-l">48</div>
	<p>< 1% match (publications)</p>

	<a style="color:#630000" href="http://dx.doi.org/10.1016/j.ins.2010.08.045">Mussi, L.. "Evaluation of parallel particle swarm optimization algorithms within the CUDA(TM) architecture", Information Sciences, 20111015</a>

	</div>
	<div>
	<div class="number-l">49</div>
	<p>< 1% match (student papers from 06-Jul-2012)</p>

	<a style="color:#009cff" href="/paperInfo.asp?r=13.9568054433109&svr=1&lang=en_us&oid=257208418&perc=0">Submitted to Universiti Sains Malaysia on 2012-07-06</a>

	</div>
	<div>
	<div class="number-l">50</div>
	<p>< 1% match (Internet from 25-Jul-2012)</p>

	<a style="color:#31ff00" href="http://www.marketsandmarkets.com/Market-Reports/silicon-carbide-electronics-market-439.html">http://www.marketsandmarkets.com/Market-Reports/silicon-carbide-electronics-market-439.html</a>

	</div>
	<div>
	<div class="number-l">51</div>
	<p>< 1% match (Internet from 24-Aug-2011)</p>

	<a style="color:#330099" href="http://www.coursehero.com/file/1343675/TR04-10/">http://www.coursehero.com/file/1343675/TR04-10/</a>

	</div>
	<div>
	<div class="number-l">52</div>
	<p>< 1% match (publications)</p>

	<a style="color:#00cc99" href="http://dx.doi.org/10.1016/B978-0-12-388426-8.00007-0">"Techniques to Increase Parallelism", CUDA Application Design and Development, 2011</a>

	</div>
	<div>
	<div class="number-l">53</div>
	<p>< 1% match (publications)</p>

	<a style="color:#ff0063" href="http://dx.doi.org/10.1109/TSMCC.2012.2215851">Behdad, Mohammad, Luigi Barone, Mohammed Bennamoun, and Tim French. "Nature-Inspired Techniques in the Context of Fraud Detection", IEEE Transactions on Systems Man and Cybernetics Part C (Applications and Reviews), 2012.</a>

	</div>
	<div>
	<div class="number-l">54</div>
	<p>< 1% match (Internet from 04-Sep-2010)</p>

	<a style="color:#006331" href="http://lrd.yahooapis.com/_ylc=X3oDMTVnOTdnMnR1BF9TAzIwMjMxNTI3MDIEYXBwaWQDTHJlazRUTFYzNEdRVjYwVDFRYVlHeC5xMDYuMHVja2pJb3dfYzJFV3NGejhWZzVHX2xkQjRPX1YweDZPdVNOME9zVjg2a0I2BGNsaWVudANib3NzBHNlcnZpY2UDQk9TUwRzbGsDdGl0bGUEc3JjcHZpZAMxX3h2T2tnZUF1ME9lZXFGb3ptQVJ0eElKbS5UVGt5RE03WUFDR2hK/SIG=11i81vhnl/**http%3A//sequoia.stanford.edu/source/manual.pdf">http://sequoia.stanford.edu/source/manual.pdf</a>

	</div>
	<div>
	<div class="number-l">55</div>
	<p>< 1% match (Internet from 24-Apr-2012)</p>

	<a style="color:#9966ff" href="http://home.dei.polimi.it/sami/architetture_avanzate/gpu.pdf">http://home.dei.polimi.it/sami/architetture_avanzate/gpu.pdf</a>

	</div>
	<div>
	<div class="number-l">56</div>
	<p>< 1% match (Internet from 07-Mar-2011)</p>

	<a style="color:#9c6331" href="http://hps.ece.utexas.edu/pub/TR-HPS-2010-006.pdf">http://hps.ece.utexas.edu/pub/TR-HPS-2010-006.pdf</a>

	</div>
	<div>
	<div class="number-l">57</div>
	<p>< 1% match (publications)</p>

	<a style="color:#ce0031" href="http://dx.doi.org/10.1016/j.patrec.2009.09.011">Jain, A.K.. "Data clustering: 50 years beyond K-means", Pattern Recognition Letters, 20100601</a>

	</div>
	<div>
	<div class="number-l">58</div>
	<p>< 1% match (publications)</p>

	<a style="color:#cc9900" href="">Pangborn, Andrew D. "Scalable data clustering using GPUs", Proquest, 20111108</a>

	</div>
	<div>
	<div class="number-l">59</div>
	<p>< 1% match (publications)</p>

	<a style="color:#63009c" href="">Jalili-Marandi, Vahid. "Acceleration of transient stability simulation for large-scale power systems on parallel and distributed hardware", Proquest, 20111109</a>

	</div>
	<div>
	<div class="number-l">60</div>
	<p>< 1% match (publications)</p>

	<a style="color:#cc6600" href="http://dx.doi.org/10.1007/978-3-642-19460-3_4">Bing Liu. "Unsupervised Learning", Web Data Mining, 2011</a>

	</div>
	<div>
	<div class="number-l">61</div>
	<p>< 1% match (student papers from 28-Jun-2011)</p>

	<a style="color:#cc0066" href="/paperInfo.asp?r=13.9568054433109&svr=1&lang=en_us&oid=192892550&perc=0">Submitted to Middle East College of Information Technology on 2011-06-28</a>

	</div>
	<div>
	<div class="number-l">62</div>
	<p>< 1% match (Internet from 26-Oct-2010)</p>

	<a style="color:#33cc99" href="http://www.cs.virginia.edu/~skadron/Papers/cuda_jpdc08.pdf">http://www.cs.virginia.edu/~skadron/Papers/cuda_jpdc08.pdf</a>

	</div>
	<div>
	<div class="number-l">63</div>
	<p>< 1% match (Internet from 04-Nov-2011)</p>

	<a style="color:#336699" href="http://lib.tkk.fi/Diss/2000/isbn9512252600/isbn9512252600.pdf">http://lib.tkk.fi/Diss/2000/isbn9512252600/isbn9512252600.pdf</a>

	</div>
	<div>
	<div class="number-l">64</div>
	<p>< 1% match (Internet from 06-Oct-2010)</p>

	<a style="color:red" href="http://www.informatica.si/PDF/33-2/24_Madzarov%20-%20A%20Multi-class%20SVM%20Classifier%20Utilizing%20Bin.pdf">http://www.informatica.si/PDF/33-2/24_Madzarov%20-%20A%20Multi-class%20SVM%20Classifier%20Utilizing%20Bin.pdf</a>

	</div>
	<div id="last">
	<div class="number-l">65</div>
	<p>< 1% match (publications)</p>

	<a style="color:green" href="http://dx.doi.org/10.1109/ISDA.2012.6416596">Zaoralek, Lukas, and Petr Gajdos. "CUDA code support in multiagent platform JADE", 2012 12th International Conference on Intelligent Systems Design and Applications (ISDA), 2012.</a>

	</div>

</div>



<div class="divider">paper text:</div>
<div id="body">
K-means Clustering Algorithm: Efficient Implementation on Graphics Processing Units by Kunjan Aggarwal <a href="javascript:openDSC(2769161780, 304, '4927');" onmouseover="doRollover(40);" onmouseout="undoRollover(40);" id="4927" name="40" style="color:#cc0066" class="#cc0066"><span class="b-ref">40</span>under the guidance of Prof.<span> Mainak Chaudhuri </span>DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING INDIAN INSTITUTE OF TECHNOLOGY</a> KANPUR March, 2013 K-means Clustering Algorithm: Efficient Implementation on Graphics Processing Units <a href="javascript:openDSC(2425783107, 43, '3383');" onmouseover="doRollover(7);" onmouseout="undoRollover(7);" id="3383" name="7" style="color:#009cff" class="#009cff"><span class="b-ref">7</span>A dissertation submitted in partial fulfillment of the requirements for the degree of MASTER OF TECHNOLOGY in COMPUTER SCIENCE &amp; ENGINEERING Submitted by<span> Kunjan Aggarwal </span>under the guidance of Prof.<span> Mainak Chaudhuri </span>DEPARTMENT OF COMPUTER SCIENCE<span> AND </span>ENGINEERING INDIAN INSTITUTE OF TECHNOLOGY<span> KANPUR March, 2013 </span>CERTIFICATE<span> It </span>is<span> certified </span>that the</a> work contained in this thesis entitled “K-means Clustering Algorithm: Efficient Implementation on Graphics Processing Units”, by Mr. Kunjan Aggarwal (Roll No. 10111021), <a href="javascript:openDSC(3473868792, 772, '6137');" onmouseover="doRollover(17);" onmouseout="undoRollover(17);" id="6137" name="17" style="color:#63009c" class="#63009c"><span class="b-ref">17</span>has been carried out under my supervision and this work has not been submitted elsewhere for a degree. Dr.<span> Mainak Chaudhuri, Associate </span>Professor, Department of Computer Sc. &amp; Engg., Indian Institute of Technology, Kanpur</a> Kanpur, 208016. <a href="javascript:openDSC(2425783107, 43, '3406');" onmouseover="doRollover(7);" onmouseout="undoRollover(7);" id="3406" name="7" style="color:#009cff" class="#009cff"><span class="b-ref">7</span>i<span> ACKNOWLEDGMENTS I </span>am greatly indebted to my supervisor Prof.</a> Mainak Chaudhuri for his encour- agement, patience and expert advice throughout the course of my study at IIT Kanpur. In spite of his busy schedule, he has always been there to help me and provide me his invaluable technical guidance and moral support. He always gave me the right direction to focus on. Special thanks to all my classmates of the MTech’10 batch of the Dept. of Computer Science and Engineering at IIT Kanpur for their constructive criticism of my work and for helping me out with various issues during the study. I especially thank Ajith Sankar for offering intuitive ideas and brain storming sessions. My family is my source of inspiration and this thesis would have been incomplete without their support. It is my father Mr Vijay Kumar Aggarwal and my mother Mrs Sunita Aggarwal’s endurance and patience that kept me motivated at all times. I could not have been successful without the never ending support from my brother Abhishek Aggarwal and my sister Sugandha Aggarwal. <a href="javascript:openDSC(2583680307, 943, '7013');" onmouseover="doRollover(63);" onmouseout="undoRollover(63);" id="7013" name="63" style="color:#336699" class="#336699"><span class="b-ref">63</span>Finally, I would<span> once again </span>like to thank all my friends for</a> insightful discussions, suggestions and encouragement. Kunjan Aggarwal March, 2013 ii ABSTRACT Data analysis and classification play a big role in understanding various real life phenomena. Clustering helps analyze data with little or no prior knowledge about it. <a href="javascript:openDSC(37950976, 37, '9568');" onmouseover="doRollover(5);" onmouseout="undoRollover(5);" id="9568" name="5" style="color:#ff6600" class="#ff6600"><span class="b-ref">5</span>K-means<span> clustering </span>is a popular clustering algorithm with applications<span> to </span>computer vision, data mining, data<span> visualization, </span>etc..</a><a href="javascript:openDSC(38304734, 37, '9467');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="9467" name="2" style="color:green" class="green"><span class="b-ref">2</span>Due to continuously increasing data volume, parallel computing is<span> necessary to overcome </span>the</a> computational challenges involved in K-means clustering. <a href="javascript:openDSC(37950976, 37, '9573');" onmouseover="doRollover(5);" onmouseout="undoRollover(5);" id="9573" name="5" style="color:#ff6600" class="#ff6600"><span class="b-ref">5</span>We present the design and implementation of K- means clustering algorithm on</a> widely available graphics processing units (GPUs), which have the required hardware architecture to meet these parallelism needs. We analyze the scalability of our proposed methods with increase in number and dimensionality of data points as well as the number of clusters. We also compare our results with current best available implementations on GPUs and a 24-way threaded parallel CPU implementation. We achieved a consistent speedup of 6.5x over the parallel CPU implementation. <a href="javascript:openDSC(2758587602, 304, '4952');" onmouseover="doRollover(24);" onmouseout="undoRollover(24);" id="4952" name="24" style="color:blue" class="blue"><span class="b-ref">24</span>iii Contents<span> Certificate </span>i<span> Acknowledgments </span>ii<span> Abstract </span>iii Contents iv List of Figures vii List of Tables ix<span> 1 </span>Introduction 1 1.1<span> Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . </span>1 1.2<span> Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 </span>1.</a> 3 Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 2 K-means Clustering <a href="javascript:openDSC(1430671150, 943, '6688');" onmouseover="doRollover(51);" onmouseout="undoRollover(51);" id="6688" name="51" style="color:#330099" class="#330099"><span class="b-ref">51</span>Algorithm 4 2.1 Background ................................ 4 2.2 Algorithm ................................. 4 2.3</a> Analysis .................................. 5 2.3.1 Finding nearest centroids . . . . . . . . . . . . . . . . . . . . . 7 2.3.2 Computing new centroids . . . . . . . . . . . . . . . . . . . . 7 2.4 NU-MineBench: A CPU Benchmark . . . . . . . . . . . . . . . . . . 7 2.4.1 Implementation Details . . . . . . . . . . . . . . . . . . . . . . 8 iv 2.4.2 Our Modifications . . . . . . . . . . . . . . . . . . . . . . . . . 9 3 CUDA: A General Purpose Parallel Computing Architecture 11 3.1 GPU Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 <a href="javascript:openDSC(237604601, 1274, '7452');" onmouseover="doRollover(50);" onmouseout="undoRollover(50);" id="7452" name="50" style="color:#31ff00" class="#31ff00"><span class="b-ref">50</span>3.1.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.1.2<span> Memory Hierarchy . . . . . . . . . . . . . . . . . . . . . . . . 14 </span>3.1.3<span> Hardware Multithreading . . . . . . . . . . . . . . . . . . . . 15 </span>3.</a> 2 CUDA API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 3.2.1 CUDA Execution Model . . . . . . . . . . . . . . . . . . . . . 17 3.2.2 CUDA C Runtime . . . . . . . . . . . . . . . . . . . . . . . . 18 4 Finding Nearest Centroid 21 4.1 Special Case: Low-dimensional Input . . . . . . . . . . . . . . . . . . 22 4.1.1 Storage of data points . . . . . . . . . . . . . . . . . . . . . . 22 4.1.2 Loading of data points . . . . . . . . . . . . . . . . . . . . . . 22 4.1.3 Loading of centroids . . . . . . . . . . . . . . . . . . . . . . . 24 4.2 Generic Implementation . . . . . . . . . . . . . . . . . . . . . . . . . 28 4.2.1 Loading of data points . . . . . . . . . . . . . . . . . . . . . . 28 4.2.2 Loading of centroids . . . . . . . . . . . . . . . . . . . . . . . 29 4.2.3 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4.2.4 Scalability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 5 Compute New Centroids 32 5.1 Intra-block Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 5.1.1 Checking membership . . . . . . . . . . . . . . . . . . . . . . 34 5.1.2 Reduce member co-ordinates . . . . . . . . . . . . . . . . . . . 35 5.1.3 Store reduced values . . . . . . . . . . . . . . . . . . . . . . . 36 5.2 Inter-block Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 6 Experimental Results 38 6.1 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 v 6.2 Comparison with CPU . . . . . . . . . . . . . . . . . . . . . . . . . . 38 6.3 Comparison with Published Results . . . . . . . . . . . . . . . . . . . 40 7 Conclusions and Future Work 42 Bibliography 43 vi List of Figures 2.1 2.2 <a href="javascript:openDSC(2770047976, 304, '2498');" onmouseover="doRollover(15);" onmouseout="undoRollover(15);" id="2498" name="15" style="color:#ce0031" class="#ce0031"><span class="b-ref">15</span>Illustration of<span> the </span>K-means Algorithm<span> 1 for </span>two-dimensional data</a> points when number of clusters, K = 3 . . . . . . . . . . . . . . . . . 6 Execution times of NU-MineBench based K-means Algorithm 2 for 100 iterations on Record Linkage Dataset [27], with K = 2, d = 9, n = 5749132. (a) Original NU-MineBench shows slight increase in execution time with increase in thread count due to latencies caused by false sharing. (b) Modified NU-MineBench shows linear speedup with increase in thread count. . . . . . . . . . . . . . . . . . . . . . . 10 3.1 Block Diagram of G100 Fermi GPU containing 16 Streaming Multi- processors (SMs) (Source: NVIDIA [23]). . . . . . . . . . . . . . . . . 12 3.2 Block Diagram of Fermi Streaming Multiprocessor (SM) containing 32 cores (Source: NVIDIA [23]). . . . . . . . . . . . . . . . . . . . . . 13 3.3 3.4 CUDA memory hierarchy. (Source: NVIDIA [10]). . . . . . . . . . . . 14 Single-Instruction, Multiple-Thread (SIMT) warp execution on Fermi.(Source: 3.5 NVIDIA [23]). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 CUDA software stack.(Source: NVIDIA). . . . . . . . . . . . . . . . . 17 vii 5.1 Illustration of intra-block reduction performed by a warp w on data points i to i + 31. (a) Threads t1 to t32 load the membership values for points i to i + 31. (b) Each thread stores boolean isM ember for corresponding data point into shared memory. (c) All 32 threads check value of isM ember for each point till they find point i + p with value 1. (d) Successive co-ordinates of point i + p are added by successive threads into their private arrays. . . . . . . . . . . . . . . . 34 6.1 Comparison of execution time of our implementation of K-means with Li et al [17], University of Virginia [4] and GPUMiner [9] for 100 iterations on KDD Cup 1999 Dataset [15], with K = 32, d = 34, n = 51200 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 viii List of Tables 4.1 Comparison of runtime for 50 iterations of label assignment on C1060 for low-dimensional data with different access locations for centroid. . 26 4.2 Comparison of runtime for 50 iterations of label assignment on C2070 for low-dimensional data with different access locations for centroid. . 27 4.3 Change in device memory read overhead with increase in distance updations per read on C1060 for n=819200, d=34, K=32 in a single kernel iteration of generic findCluster. . . . . . . . . . . . . . . . . . . 30 6.1 KDD Cup 1999 Data Set: Execution times for K-means on CPU and 6.2 GPU. K = 64, d = 41, number of iterations= 50 . . . . . . . . . . . . 39 KDD Cup 1999 Data Set: Execution times for K-means on CPU and 6.3 GPU. n = 2000000, d = 41, number of iterations= 50 . . . . . . . . . 39 Covertype Data Set: Execution times for K-means on CPU and GPU. 6.4 K = 64, d = 54, number of iterations= 50. . . . . . . . . . . . . . . . 40 Covertype Data Set: Execution times for K-means on CPU and GPU. 6.5 n = 500000, d = 54, number of iterations= 50. . . . . . . . . . . . . . 40 Comparison of execution times of our K-means implementation with timings in Li et al [17]. K = 32, n = 51200, number of iterations= 100. 41 ix Chapter 1 Intro duction 1.1 Introduction <a href="javascript:openDSC(31611094, 37, '12839');" onmouseover="doRollover(21);" onmouseout="undoRollover(21);" id="12839" name="21" style="color:#336699" class="#336699"><span class="b-ref">21</span>“Understanding our world requires conceptualizing the similarities and differences between the entities that compose it”</a> [32]. For understanding phenomena in real life there is always a need to aggregate all the raw data and then perform analysis over it. Various methodologies have been adopted for analyzing the raw data both for performing supervised and unsupervised learning. Clustering is one such technique, an unsupervised classification or exploratory data analysis without availability of any labeled data [35]. It aids in organizing the data instances <a href="javascript:openDSC(2902143589, 43, '3617');" onmouseover="doRollover(14);" onmouseout="undoRollover(14);" id="3617" name="14" style="color:#9c6331" class="#9c6331"><span class="b-ref">14</span>into an efficient representation that characterizes the<span> data </span>being sampled. Formally,</a><a href="javascript:openDSC(2902143589, 43, '3615');" onmouseover="doRollover(14);" onmouseout="undoRollover(14);" id="3615" name="14" style="color:#9c6331" class="#9c6331"><span class="b-ref">14</span>clustering groups data instances into subsets in such a manner that similar instances are grouped together, while different instances belong to different groups<span> [28]. </span>The</a><a href="javascript:openDSC(38881171, 487, '10702');" onmouseover="doRollover(12);" onmouseout="undoRollover(12);" id="10702" name="12" style="color:#006331" class="#006331"><span class="b-ref">12</span>goal of clustering is to separate a finite, unlabeled data set into a finite and discrete set of “natural”, hidden data structures, rather than to<span> pro- vide </span>an accurate characterization of unobserved samples generated from the same probability distribution</a> [2, 6]. There are <a href="javascript:openDSC(2770047976, 304, '2523');" onmouseover="doRollover(15);" onmouseout="undoRollover(15);" id="2523" name="15" style="color:#ce0031" class="#ce0031"><span class="b-ref">15</span>a large number of clustering algorithms<span> and heuristics that </span>have been developed</a> over the last many decades [13, 28, 35]. Since these clustering algorithms have to analyze real world data, they often have to deal with huge datasets that 1 CHAPTER 1. INTRODUCTION require high processing power. <a href="javascript:openDSC(2457960447, 772, '5959');" onmouseover="doRollover(56);" onmouseout="undoRollover(56);" id="5959" name="56" style="color:#9c6331" class="#9c6331"><span class="b-ref">56</span>Over the<span> last </span>few years, Graphics Processing Units (GPUs) have<span> emerged as </span>a<span> new alternative </span>for</a> handling operations with high levels of parallelism [16]. Also since the data operations in clustering algorithms are largely independent and compute-intensive, the large number of cores available on GPUs offer a more natural alternative for extracting maximum parallelism and efficiency [4]. In our work, we will be looking at <a href="javascript:openDSC(37950976, 37, '9575');" onmouseover="doRollover(5);" onmouseout="undoRollover(5);" id="9575" name="5" style="color:#ff6600" class="#ff6600"><span class="b-ref">5</span>design and implementation of K-means<span> clus- tering </span>algorithm on</a> GPUs <a href="javascript:openDSC(2651386446, 1390, '8613');" onmouseover="doRollover(47);" onmouseout="undoRollover(47);" id="8613" name="47" style="color:#ff6600" class="#ff6600"><span class="b-ref">47</span>using a general-purpose parallel programming model, namely Compute Unified Device Architecture (CUDA)</a> [24]. We analyze the scala- bility of our proposed methods with increase in number and dimensionality of data points as well as the number of clusters. We also compare our results with cur- rent best available implementations on GPUs and 24-way threaded parallel CPU implementations. 1.2 Related work The K-means algorithm was independently proposed by Hugo Steinhaus in 1956 [30], Stuart Lloyd in 1957 [18], Ball &amp; Hall in 1965 [1] and James MacQueen in 1967 [20]. Because of its efficiency in clustering large data sets it is one of the most popular and commonly used partitional algorithm [14]. It has been successfully used for analysis in variety of different fields like economics (market segmentation), life and medical sciences (genetics, microbiology), engineering (machine learning), astronomy, earth sciences and sociology (behavior pattern discovery) [35]. Initial <a href="javascript:openDSC(41274837, 37, '13426');" onmouseover="doRollover(30);" onmouseout="undoRollover(30);" id="13426" name="30" style="color:#330099" class="#330099"><span class="b-ref">30</span>implementations of K-means clustering algorithm on</a> GPUs have been reported by Takizwa et al [31] and Cao et al [3] in 2006. Ma et al [19] made a generic translation system to port CPU code over GPUs and were able to get 20x speedup over original sequential CPU implementation. In 2007, a team at University of Virgina implemented K-means on G80 GPU and reported 8x speedup in comparison to a single threaded Pentium 4 processor [5]. Later in 2008, they CHAPTER 1. INTRODUCTION revised their work and were able to achieve 35x speedup on GTX 260 GPU over a dual core CPU [4]. In 2008, another team at Hong Kong University of Science and Technology introduced GPUMiner suite [9], which contained <a href="javascript:openDSC(40137193, 37, '9621');" onmouseover="doRollover(6);" onmouseout="undoRollover(6);" id="9621" name="6" style="color:#630000" class="#630000"><span class="b-ref">6</span>parallel data mining<span> implementations </span>on graphics processors.</a> They reported 5x improvement over the first work [5] done by University of Virgina but it was still slower than their later implementation [4]. In 2009, a team of researchers at HP labs further improved these results [34]. They achieved upto 4x speedup over university of Virgina’s implementation [4] and 20x to 70x speedup over GPUMiner [9]. This work was further improved by Li et al [17] in 2010 by making separate K-means implementations <a href="javascript:openDSC(38304734, 37, '9470');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="9470" name="2" style="color:green" class="green"><span class="b-ref">2</span>for low dimensional and<span> higher </span>dimensional<span> input </span>data sets. In</a> 2011, Wasif et al [33] reported 2x im- provement over work of Li et al [17]. They have also reported 70x speedup on Fermi architecture based GTX480 GPU over a 32 bit Intel Core 2 duo processor. <a href="javascript:openDSC(340497178, 5, '2945');" onmouseover="doRollover(45);" onmouseout="undoRollover(45);" id="2945" name="45" style="color:blue" class="blue"><span class="b-ref">45</span>1.3 Outline The rest of the thesis is organized as follows:<span> In </span>Chapter 2,</a> we give an introduction to K-means clustering algorithm. We illustrate its different stages and then analyze its complexity and scalability. Also, we take a look into NU-MineBench benchmark suite [26] which we have used for our CPU implementations. Chapter 3 gives an overview of GPU architecture of NVIDIA’s Tesla and Fermi graphics processing units. It also provides a short introduction to Compute Unified Device Architec- ture (CUDA) API which we have used to implement K-means on NVIDIA GPUs. Chapters 4 and 5 present details of our implementation of K-means algorithm. In Chapter 6 we show comparison of our approach with the current published results. Also, we present comparison of our results on NVIDIA GPUs with 24-way threaded parallel CPU implementations for real world datasets. Finally, Chapter 7 concludes our work and presents scope for future research. Chapter 2 K-means Clustering Algorithm 2.1 Background <a href="javascript:openDSC(2367096215, 43, '3346');" onmouseover="doRollover(3);" onmouseout="undoRollover(3);" id="3346" name="3" style="color:blue" class="blue"><span class="b-ref">3</span>Even though K-means was first proposed over<span> fifty </span>years ago, it is still one of the most widely used algorithms for clustering. Ease of implementation, simplicity, efficiency, and empirical success are the main reasons for its popularity.<span> The main features </span>of<span> the conventional </span>K-means<span> clustering algorithm [12] </span>are</a> as follows. 1. It is a partitional or non-hierarchical clustering method. 2. The total <a href="javascript:openDSC(2770047976, 304, '2517');" onmouseover="doRollover(15);" onmouseout="undoRollover(15);" id="2517" name="15" style="color:#ce0031" class="#ce0031"><span class="b-ref">15</span>number of clusters,<span> k, </span>is assumed to be<span> fixed and </span>known</a> before hand. 3. It uses Euclidean distance as the criterion for finding distance between the data points and hence, is only applicable to numerical data. 4. It is a greedy iterative method and the iterations continue till the error function has not reached a threshold or the membership of the data points no longer changes. 2.2 <a href="javascript:openDSC(2367096215, 43, '3351');" onmouseover="doRollover(3);" onmouseout="undoRollover(3);" id="3351" name="3" style="color:blue" class="blue"><span class="b-ref">3</span>Algorithm Let<span> D = </span>{xi, i = 1, ..., n} be the<span> given input data </span>set of d dimensional<span> data </span>points.<span> Let K </span>be</a> the total number of disjoint clusters, denoted by C = {ck, k = 1, ..., K}. 4 For each cluster ck let µ(ck) be its centroid or mean. Then the error function is defined as K E (C) = ∑ ∑ ‖x − µ (ck) ‖2 k=1 xɛck The aim <a href="javascript:openDSC(29257043, 37, '10002');" onmouseover="doRollover(57);" onmouseout="undoRollover(57);" id="10002" name="57" style="color:#ce0031" class="#ce0031"><span class="b-ref">57</span>of K-means is to minimize the<span> value </span>of the error<span> function E </span>(C))</a> which is an NP-hard problem [8]. The pseudo code for conventional <a href="javascript:openDSC(40470157, 37, '9650');" onmouseover="doRollover(8);" onmouseout="undoRollover(8);" id="9650" name="8" style="color:#31ff00" class="#31ff00"><span class="b-ref">8</span>K-means algorithm is<span> shown </span>in Algorithm 1. Algorithm 1 K-means</a> Algorithm Input Dataset D containing n d-dimensional points, Number of clusters K, Error threshold Et Output K disjoint clusters, C = {ck, k = 1, ..., K} with their members. 1. {c1, c2, ..., ck} be the initial K partitions. <a href="javascript:openDSC(34763965, 37, '14428');" onmouseover="doRollover(60);" onmouseout="undoRollover(60);" id="14428" name="60" style="color:#cc6600" class="#cc6600"><span class="b-ref">60</span>2. repeat 3. for each data-point x<span> in </span>D do 4.</a> Let x belongs to cluster c1. 5. mindist ← ‖x − µ (c1) ‖2 6. for each centroid µ do 7. dist ← ‖x − µ‖2 8. If dist &lt; mindist, assign x to µ 9. end for 10. end for 11. Recompute the cluster centroids based on above assignments. 12. Calculate the error function E (C). 13. until either there were no changes in cluster membership or value of E (C) &lt; Et. 2.3 Analysis K-means algorithm tries to terminate at a local optimum. It always converges to a local minimum point [29] after a finite number of iterations and so the value of error function E(C) is always non-increasing. The most important choice for K-means algorithm is the choice of value K. Also, the final set <a href="javascript:openDSC(31611094, 37, '12848');" onmouseover="doRollover(21);" onmouseout="undoRollover(21);" id="12848" name="21" style="color:#336699" class="#336699"><span class="b-ref">21</span>of clusters and the number of iterations taken to</a> reach them is dependent on the initially selected centroids (Step 1 in Algorithm 1). Figure 2.2 illustrates the execution of K-means Algorithm 1. We consider the case where the input data points are two-dimensional and the value of K is 3. Figure 2.1a shows the initialization phase (Step 1) of the algorithm. (a) Initial Phase (b) 1st Assignment (c) 1st Re-computation (d) 2nd Assignment (e) 2nd Re-computation (f) Final Assignment Figure 2.1: <a href="javascript:openDSC(2770047976, 304, '2502');" onmouseover="doRollover(15);" onmouseout="undoRollover(15);" id="2502" name="15" style="color:#ce0031" class="#ce0031"><span class="b-ref">15</span>Illustration of<span> the </span>K-means Algorithm<span> 1 for </span>two-dimensional data</a> points when number of clusters, K = 3 Three random data-points have been selected as the initial centroids. In the first it- eration, the assignment stage (Step 3) assigns the data points to the initial centroids based on their Euclidean distance with the initially selected centroids as depicted in Figure 2.1b. In the re-computation stage, (Step 11) the centroids are re-computed to their new values (Figure 2.1c). In the second iteration, during assignment of data points many points change their cluster (Figure 2.1d). Due to this re-assignment there is again a shift in the positions of the centroids (Figure 2.1e). As we can visually see, the centroids are moving closer to the actual cluster centers with each iteration. This gives a general idea of how the algorithm converges to the final clusters and why the value of error function E (C) keeps on decreasing with each iteration [29]. Finally, in the third and last iteration assignment stage does not produce any reassignments (Figure 2.1f). Since this was our termination condition (Step 13), the algorithm exits and outputs the final clusters with their members. 2.3.1 Finding nearest centroids During assignment of the n data points, distance of each data point is calculated from all the K clusters. Assuming input data to be d-dimensional, this takes O(nKd) time. Finding the minimum distance out of the K distances for all n data points takes O(nK) time. Thus, the total time complexity of this step is O(nKd + nK). For large input data sets, values of d and K are much smaller as compared to n. As a result, we can consider this step to be linear in terms of n. Also, the extra space required is for storing the membership of the data points which anyways is required in the output and is again O(n). Hence, the time and space complexity have a linear increase with increase in the size of input data set, making it highly scalable. 2.3.2 Computing new centroids While computing new centroids, value µ is calculated for each of the K clusters. This requires taking mean of all the members for every cluster. Since these clusters are disjoint, mean calculation of all the K clusters has a time complexity of O(nd). Again for large data sets this can be considered linear in terms of n. For storing the computed K centroids it requires O(Kd) extra space. Hence, this step too is linear in terms of n making the complete K-means algorithm linear and very efficient for large sized data sets. 2.4 NU-MineBench: A CPU Benchmark In this section we will take a look at NU-MineBench data mining benchmark suite [26] developed at Northwestern University. This suite contains parallel implemen- tations of various data mining algorithms, including K-means, on CPU. Previous authors [4, 9, 34] have used NU-MineBench for their CPU implementation of K- means while comparing runtime of their GPU implementations with CPU. That’s why, we too decided to use the same to benchmark our work on GPU against CPU. 2.4.1 Implementation Details NU-MineBench uses OpenMP API [25] to execute K-means in parallel across max- imum possible threads available on CPU. The CPU-based implementation is illus- trated in Algorithm 2. Algorithm 2 K-means Algorithm from NU-MineBench Input Dataset data[n][d], Number of clusters K, Maximum iterations Mitr Output centroid[K][d], membership[n]. 1. for each cluster k in K do 2. for each dimension di in d do 3. centroid[k][di] ← data[k][di] 4. end for 5. end for 6. Let T be maximum number of threads. 7. repeat 8. Partition the n data points equally among all T threads. 9. Initialize all values in newClusterSize[T][K] to 0. 10. Initialize all values in newCentroid[T][K][d] to 0. 11. Start parallel execution for each thread t in T. 12. for each data-point p do 13. Compute nearest centroid k amongst centroid[K][d]. 14. membership[p] ← k 15. newClusterSize[t][k]++ 16. for each dimension di in d do 17. newCentroid[t][k][di] += data[p][di] <a href="javascript:openDSC(37950976, 37, '9582');" onmouseover="doRollover(5);" onmouseout="undoRollover(5);" id="9582" name="5" style="color:#ff6600" class="#ff6600"><span class="b-ref">5</span>18. end<span> for </span>19. end for 20. End<span> parallel execution. 21. </span>for</a> each cluster k in K do 22. for each thread t in T do 23. newClusterSize[0][k] += newClusterSize[t][k] 24. for each dimension di in d do 25. newCentroid[0][k][di] += newCentroid[t][k][di] 26. centroid[k][di] ← newCentroid[0][k][di]/newClusterSize[0][k] 27. end for 28. end for 29. end for 30. until either there were no changes in membership[] or maximum iterations Mitr have been completed. Since, it is hard to know the number of iterations it might take for the K-means to end, NU-MineBench takes the maximum number of iterations Mitr as an additional input. Step 1 initializes the first <a href="javascript:openDSC(38304734, 37, '9479');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="9479" name="2" style="color:green" class="green"><span class="b-ref">2</span>K data points as the initial centroids.</a> During assignment of data points (Step 8) to their nearest centroids, maximum possible threads are launched on CPU. The data points are equally partitioned among all the threads. For independent parallel execution, each thread maintains its own cluster variables, newClusterSize containing the number of points that are member of each cluster and newCentroid storing the sums of dimensions of all the assigned data points for every cluster. For every data point, index of its nearest cluster is stored in membership variable and the newClusterSize and newCentroid variables of that centroid are updated. After all the threads have finished evaluating their data points and stored values in their respective newClusterSize and newCentroid variables, the parallel execu- tion ends. Now a single thread (main thread) reduces these values obtained by each thread for every cluster (Step 21). In the end, the <a href="javascript:openDSC(827137426, 772, '2586');" onmouseover="doRollover(62);" onmouseout="undoRollover(62);" id="2586" name="62" style="color:#33cc99" class="#33cc99"><span class="b-ref">62</span>new centroids are<span> computed </span>by taking mean of all the data</a> points that had been assigned to each cluster and are assigned to centroid[]. At the end of an iteration, if there was no change in membership[] or if we have finished Mitr iterations than centroid[] and membership[] are returned as the final results of K-means. 2.4.2 Our Modifications NU-MineBench’s performance relies heavily on cache utilization. To avoid any shared memory conflicts between the parallel executing threads, local variables newClusterSize and newCentroid are maintained separately for each thread. Also, while computing new centroids (Step 21) only a single thread is used because the overhead of launching multiple threads to perform a tree-based reduction is much higher than doing flat reduction using a single thread. This is based on the as- sumption that the total number of available threads are going to be low keeping the number of values to be reduced small. But we found that speedup achieved with NU-MineBench decreases as the value of K is lowered. In fact, for K = 2, we saw an increase in execution time with increase in thread count; see Figure 2.2a. On investigation we found false sharing to be the limiting factor. While assigning memory for variable newClusterSize, a continuous memory space of size T ∗ K ∗ sizeof(int) bytes is allocated in memory, where first K positions are updated by first thread, next K by second thread and so on. When the value of K is small it is possible that values for multiple threads reside in the same cache block. This results in multiple threads updating the same cache block and so the participant threads have to update the values in their cache with changes done by other threads before doing a read. (a) Original NU-MineBench (b) Modified NU-MineBench Figure 2.2: Execution times of NU-MineBench based K-means Algorithm 2 for 100 iterations on Record Linkage Dataset [27], with K = 2, d = 9, n = 5749132. (a) Original NU-MineBench shows slight increase in execution time with increase in thread count due to latencies caused by false sharing. (b) Modified NU-MineBench shows linear speedup with increase in thread count. To overcome this shortcoming we ensure that the values stored by each thread occupy distinct cache blocks. We separate every set of K indices inside the array newClusterSize with unused memory locations. We also make similar changes for newCentroid array. This ensures that even for smaller values of K the speedup obtained is linear in thread count; see Figure 2.2b. Also, since the size of the cache block is generally small (typically 64 bytes), this change does not make any significant impact on the overall memory requirement. Chapter 3 CUDA: A General Purpose Parallel Computing Architecture The first ever commercial graphics processing unit (GPU) was designed by NVIDIA in 1999. Because of the ever increasing demand for producing real-time graphics, which requires high arithmetic throughput, manufacturers have always focused on increasing the parallel processing capabilities of the GPUs. Today, GPUs outperform CPUs both in arithmetic processing efficiency and memory bandwidth [11, 21]. Since 2003, efforts have been made to use GPUs even for non-graphics appli- cations, especially for scientific work so that their high arithmetic throughput can be fully exploited. In our work we have used NVIDIA’s Tesla C1060 and Fermi- based Tesla C2070 GPU cards. For implementing K-means algorithm on GPU, we have used Compute Unified Device Architecture (CUDA) [24] API. This chapter will provide a brief introduction to NVIDIA’s GPU architecture and CUDA API. More detailed information is available in literature published by NVIDIA [22, 23] and in books written by Farber [10] and Kirk [16]. 11 3.1 GPU Architecture 3.1.1 Overview Tesla C2070 is based on NVIDIA’s Fermi architecture. It contains <a href="javascript:openDSC(37869251, 37, '13310');" onmouseover="doRollover(9);" onmouseout="undoRollover(9);" id="13310" name="9" style="color:#330099" class="#330099"><span class="b-ref">9</span>448 CUDA cores.<span> These cores </span>are organized in 14 Streaming<span> Multiprocessors </span>(SMs)<span> each containing </span>32 cores</a> or Streaming Processors(SP). Figure 3.1 shows block diagram of Fermi GF100 GPU containing 16 SMs, two more than C2070 GPU card that we have used for our work. Figure 3.1 also shows <a href="javascript:openDSC(33039417, 37, '14406');" onmouseover="doRollover(19);" onmouseout="undoRollover(19);" id="14406" name="19" style="color:#cc0066" class="#cc0066"><span class="b-ref">19</span>six 64-bit<span> DRAM </span>memory partitions<span> that provide </span>a 384-bit memory interface.</a> C2070 can support 6GB of GDDR5 DRAM memory. For <a href="javascript:openDSC(37950976, 37, '9579');" onmouseover="doRollover(5);" onmouseout="undoRollover(5);" id="9579" name="5" style="color:#ff6600" class="#ff6600"><span class="b-ref">5</span>data transfer between CPU and GPU<span> there </span>is a</a> host interface connecting GPU with CPU via PCI-Express. Figure 3.1: Block Diagram of G100 Fermi GPU containing 16 Streaming Multipro- cessors (SMs) (Source: NVIDIA [23]). Fermi uses a GigaThread global scheduler to distribute execution blocks between the SMs. Each SM contains unified graphics and computing multiprocessors <a href="javascript:openDSC(12522508, 37, '10216');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="10216" name="1" style="color:red" class="red"><span class="b-ref">1</span>which execute vertex/geometry shader programs as well as<span> parallel </span>computing programs.</a> We will be concentrating only on the parallel computing capabilities of SMs. A typi- cal Fermi SM is shown in figure 3.2. Each SM contains 32 SIMT (Single-Instruction, Multiple-Thread) cores. Figure 3.2: <a href="javascript:openDSC(37869251, 37, '13308');" onmouseover="doRollover(9);" onmouseout="undoRollover(9);" id="13308" name="9" style="color:#330099" class="#330099"><span class="b-ref">9</span>Block Diagram of Fermi Streaming Multiprocessor (SM)</a> containing 32 cores (Source: NVIDIA [23]). <a href="javascript:openDSC(283735806, 1, '14187');" onmouseover="doRollover(46);" onmouseout="undoRollover(46);" id="14187" name="46" style="color:brown" class="brown"><span class="b-ref">46</span>Each core<span> contains </span>a fully pipelined integer arithmetic logic unit (ALU) and<span> float- ing </span>point unit (FPU).</a> Also, there are sixteen load/store units (LD/ST) to calculate <a href="javascript:openDSC(37869251, 37, '13319');" onmouseover="doRollover(9);" onmouseout="undoRollover(9);" id="13319" name="9" style="color:#330099" class="#330099"><span class="b-ref">9</span>source and destination addresses for sixteen threads per clock.<span> Each SM contains </span>four Special Function Units (SFUs)<span> which </span>execute transcendental instructions<span> like sine, </span>cosine and square root.</a> Apart from register file, used for storing private vari- ables, each SM also contains on-chip memory that is used for caching and sharing data between the cores. The instructions are fetched from instruction cache and are dispatched to the cores by two warp schedulers. More details about the on-chip memory and the warp schedulers is provided in the later sections. 3.1.2 Memory Hierarchy Data reuse is an essential requirement for GPUs. This is due to the high latency of DRAM memory. To overcome this challenge caches have been provided, both inside SMs and also between the SMs and global memory, to cache regularly accessed data. Figure 3.3 shows various memory partitions present in Fermi. Figure 3.3: CUDA memory hierarchy. (Source: NVIDIA [10]). The global memory is stored in an external DRAM. It is used for communication between the SMs. Also any data transferred between CPU and GPU is also stored here. It is essential to coalesce global memory accesses to ensure single wide memory transactions. All the data accesses (both reads and writes) get cached in the unified L2 cache in an LRU fashion. It is 768 KB in size and helps in speeding up irregular accesses from global memory. Also it is coherent, ensuring all the cores receive updated values. To further optimize data access from global memory a separate on-chip L1 cache is also present on each SM. It only caches memory reads and any stores directly go to L2 cache. It has been provided for exploiting spatial locality and uses 128 byte wide transactions. To make the L1 cache more configurable, it can be divided into L1 cache (maintained by SM) and shared memory (programmable). Shared memory can occupy either 16 KB or 48 KB from the 64 KB L1 cache. By storing data inside shared memory, the programmer can ensure that data which has to be reused over a long period of time stays inside the on-chip cache. L1 cache is shared between all the executing cores but unlike L2, it is not coherent and requires careful measures to ensure coherence. Each executing core maintains its private data inside 32 K 32-bit registers. Dur- ing execution the registers get partitioned among the cores statically and this parti- tioning can not be reconfigured till the execution finishes. As a result, if the private data cannot fit inside the available registers, it is spilled into the local memory. Fermi tries to accommodate the spilled data inside L1 cache which may lead to eviction of cached data. Constant memory and texture memory are two other memory types present in Fermi. They both get cached on-chip and were of high importance in earlier models of NVIDIA GPUs because of unavailability of L2 and L1 caches. Constant memory is 64 KB in size and is read-only. In fact, one can get the same performance as from constant memory by declaring the data as constant inside global memory. Still, constant memory might become important if L2 cache is unable to accommodate all the data. But constant memory has a strong limitation. It only allows access of a single memory location at one time. Texture memory used to give better performance in comparison to global memory for non-coalesced data access on older GPUs. But with availability of L2 and L1 cache on Fermi, its advantage over global memory is very limited. It is more useful for visualization and shader programming. 3.1.3 Hardware Multithreading A thread is the smallest execution unit on a GPU. <a href="javascript:openDSC(33956357, 37, '11843');" onmouseover="doRollover(43);" onmouseout="undoRollover(43);" id="11843" name="43" style="color:red" class="red"><span class="b-ref">43</span>Threads are created, managed, scheduled and executed by<span> SM</span><span>’s </span>SIMT<span> multithreaded instruction </span>unit in groups of 32<span> parallel </span>threads</a> called warps. Fermi SMs contain two warp schedulers which independently schedule alternate warps (see Figure 3.4). While one warp scheduler handles all the even warps, the other handles all the odd warps. Figure 3.4: Single-Instruction, Multiple-Thread (SIMT) warp execution on Fermi.(Source: NVIDIA [23]). A SIMT warp is composed of individual threads <a href="javascript:openDSC(12522508, 37, '10223');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="10223" name="1" style="color:red" class="red"><span class="b-ref">1</span>of the same type.<span> All the threads </span>start together at the same program address.</a> Whenever the cores assigned to a warp scheduler are ready, the scheduler <a href="javascript:openDSC(12522508, 37, '10225');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="10225" name="1" style="color:red" class="red"><span class="b-ref">1</span>selects a warp that is ready to execute and issues the next instruction<span> on </span>that warp’s active threads.<span> The </span>instruction<span> gets </span>broadcast to</a> all the participant threads. Due to branching and predication, a thread may be inactive and may not execute. Whenever threads diverge, all the branches are executed serially. All the threads that do not fall on a particular path are disabled. Once all the paths have been completed the participant threads again re-converge and start executing the next instruction simultaneously. Serial execution due to <a href="javascript:openDSC(12522508, 37, '10230');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="10230" name="1" style="color:red" class="red"><span class="b-ref">1</span>branch divergence only<span> happens inside </span>a warp. Different warps<span> can </span>independently</a> execute common or disjoint paths without effecting each other. Since each warp scheduler has 16 cores to execute upon, <a href="javascript:openDSC(12522508, 37, '10233');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="10233" name="1" style="color:red" class="red"><span class="b-ref">1</span>an issued warp instruction executes as two sets of 16 threads<span> (half-warps) </span>over<span> two </span>processor cycles.<span> Also, </span>the</a> maximum number of <a href="javascript:openDSC(42211312, 37, '11939');" onmouseover="doRollover(11);" onmouseout="undoRollover(11);" id="11939" name="11" style="color:#ff0063" class="#ff0063"><span class="b-ref">11</span>warps that can reside<span> simultaneously </span>on an SM<span> gets decided by </span>the</a> availability of resources (registers and shared memory). 3.2 CUDA API 3.2.1 CUDA Execution Model During execution of CUDA programs, the program is executed with the GPU acting as a co-processor of CPU. While executing a GPU program, the code starts execution on the CPU. To ask the CPU to execute <a href="javascript:openDSC(33039417, 37, '14403');" onmouseover="doRollover(19);" onmouseout="undoRollover(19);" id="14403" name="19" style="color:#cc0066" class="#cc0066"><span class="b-ref">19</span>a piece of code on the GPU, a<span> special call called </span>kernel</a> invocation is used. It is an asynchronous call to the CUDA driver which loads the program on GPU and control immediately comes back to the CPU to execute the next instruction. Figure 3.5: CUDA software stack.(Source: NVIDIA). All transfers of data, launching of GPU computing functions (kernels) and any other interaction between CPU and GPU are handled by the runtime driver. <a href="javascript:openDSC(12522508, 37, '10237');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="10237" name="1" style="color:red" class="red"><span class="b-ref">1</span>To map a large<span> computational </span>problem<span> on the </span>highly parallel<span> GPU </span>architecture, the</a><a href="javascript:openDSC(2666635801, 43, '1792');" onmouseover="doRollover(54);" onmouseout="undoRollover(54);" id="1792" name="54" style="color:#006331" class="#006331"><span class="b-ref">54</span>problem is divided into smaller<span> independent components </span>that can be solved in parallel.</a> Before scheduling the <a href="javascript:openDSC(33039417, 37, '14409');" onmouseover="doRollover(19);" onmouseout="undoRollover(19);" id="14409" name="19" style="color:#cc0066" class="#cc0066"><span class="b-ref">19</span>large number of<span> concurrent </span>threads on<span> to </span>the GPU,<span> they </span>are</a> partitioned into disjoint components called <a href="javascript:openDSC(1393429909, 1179, '7260');" onmouseover="doRollover(55);" onmouseout="undoRollover(55);" id="7260" name="55" style="color:#9966ff" class="#9966ff"><span class="b-ref">55</span>thread blocks.<span> All </span>threads<span> in </span>a thread block<span> co-operate </span>with each other and<span> run on </span>a</a> single SM, executing the same set of instructions. Since the threads inside a block are present on the same SM, they can share the data among each other through shared memory and with constituent threads of other blocks through global memory. While threads in a single warp always execute in a synchronized manner, the threads in a thread block can also synchronize using barrier synchronization func- tions. During kernel invocation, the total <a href="javascript:openDSC(34087962, 37, '12180');" onmouseover="doRollover(48);" onmouseout="undoRollover(48);" id="12180" name="48" style="color:#630000" class="#630000"><span class="b-ref">48</span>number of thread blocks and the number of threads<span> present in each </span>block<span> need to </span>be specified.<span> On </span>the</a> basis of this informa- tion the resource usage (shared and register memory) of each block is calculated. The GigaThread scheduler then allocates maximum possible blocks to each SM. After receiving the thread blocks, SM divides them into warps and allocates them to the warp schedulers. Finally, the two warp schedulers pick up one warp each which is ready to execute and start executing instructions. The remaining blocks which could not be allocated any SM wait for the current set of blocks to finish their execution. New thread blocks are only allocated to an SM after it has finished execution of all the thread blocks currently allotted to it. 3.2.2 CUDA C Runtime For programming using CUDA, we have used CUDA’s C Runtime API. We mention here few basic functions provided by the C runtime. An exhaustive listing is present in CUDA reference manual [24]. • Kernel invocation: A kernel is declared like a normal C function except that it uses the qualifier, global . global void firstKernel (void) { } While invoking a kernel we need to pass two parameters to it which specify the way thread blocks and threads inside individual thread blocks are going to be organized. firstKernel &lt;&lt; grid size , block size &gt;&gt; (); Here grid size specifies the grid size for blocks and block size specifies the grid size for threads inside every block. <a href="javascript:openDSC(151943805, 1, '10411');" onmouseover="doRollover(32);" onmouseout="undoRollover(32);" id="10411" name="32" style="color:#ff0063" class="#ff0063"><span class="b-ref">32</span>dim3 g r i d s i z e</a> ( gx , gy , gz ) ; <a href="javascript:openDSC(151943805, 1, '10410');" onmouseover="doRollover(32);" onmouseout="undoRollover(32);" id="10410" name="32" style="color:#ff0063" class="#ff0063"><span class="b-ref">32</span>dim3 b l o c k s i z e</a> ( bx , by , bz ) ; During kernel execution, each block and every thread inside it is assigned an index on the basis of their position in the grids we defined above. • Device functions: Device functions use the qualifier device . A device function can only be invoked from code running on GPU. } device void firstDevice ( void ) { } global void firstKernel ( void ) { firstDevice (); Also, Fermi GPUs allow device functions that are recursive in nature. • Memory allocation: To allocate variables in device memory we use the function, cudaMalloc. // A <a href="javascript:openDSC(3716931677, 1390, '9231');" onmouseover="doRollover(33);" onmouseout="undoRollover(33);" id="9231" name="33" style="color:#006331" class="#006331"><span class="b-ref">33</span>l l o c a t e<span> a r r </span>a<span> y i n </span>h o s t<span> memory </span>f l o a t<span>∗ h </span>A</a> = ( <a href="javascript:openDSC(1535666465, 1274, '33');" onmouseover="doRollover(18);" onmouseout="undoRollover(18);" id="33" name="18" style="color:#cc6600" class="#cc6600"><span class="b-ref">18</span>f l o a t ∗ ) m a l l o c ( s i z e ) ; // A l l o c a t e a r r a y</a> i n <a href="javascript:openDSC(1934366988, 1390, '8428');" onmouseover="doRollover(38);" onmouseout="undoRollover(38);" id="8428" name="38" style="color:#63009c" class="#63009c"><span class="b-ref">38</span>d e v i c e<span> memory f </span>l o a t<span>∗ d </span>A<span> ; cudaMalloc ( </span>&amp;d A<span> , s i z </span>e<span> ) ; // Copy a </span>r<span> r </span>a</a> y from <a href="javascript:openDSC(26134269, 37, '12556');" onmouseover="doRollover(29);" onmouseout="undoRollover(29);" id="12556" name="29" style="color:#31ff00" class="#31ff00"><span class="b-ref">29</span>h o s t memory t o d e v i c e<span> memory </span>cudaMemcpy ( d A<span> , h </span>A<span> , s </span>i z e</a> , cudaMemcpyHostToDevice ) ; cudaMemcpy is used to copy data <a href="javascript:openDSC(257208418, 1, '11623');" onmouseover="doRollover(49);" onmouseout="undoRollover(49);" id="11623" name="49" style="color:#009cff" class="#009cff"><span class="b-ref">49</span>from host to device memory,<span> or </span>from device to<span> device </span>memory<span> and </span>from device to<span> host </span>memory.</a>• CUDA events: For performance benchmarking and runtime measurement, we have used events provided by CUDA. // Create the event variables. <a href="javascript:openDSC(2426938250, 43, '3505');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="3505" name="4" style="color:brown" class="brown"><span class="b-ref">4</span>cudaEvent t start , stop; cudaEventCreate(&amp;start); cudaEventCreate(&amp;stop);</a> // Record the event when kernel stops. cudaEventRecord(stop, 0); // Wait for the asynchronous kernel to finish. <a href="javascript:openDSC(35056242, 37, '13292');" onmouseover="doRollover(52);" onmouseout="undoRollover(52);" id="13292" name="52" style="color:#00cc99" class="#00cc99"><span class="b-ref">52</span>cudaEventSynchronize(stop);<span> // Store </span>the elapsed time. float elapsedTime; cudaEventElapsedTime ( &amp;elapsedTime, start , stop<span> ); // Record </span>the</a> event when kernel starts. cudaEventRecord(start , 0); { } firstKernel &lt;&lt; grid size ,block size &gt;&gt; (); // Finally destroy the event variables. cudaEventDestroy(start); cudaEventDestroy(stop); Chapter 4 Finding Nearest Centroid In this chapter we will create a parallel implementation for assigning data points to their nearest cluster. As explained in Section 2.3.1, the <a href="javascript:openDSC(37310718, 917, '16158');" onmouseover="doRollover(35);" onmouseout="undoRollover(35);" id="16158" name="35" style="color:#9c6331" class="#9c6331"><span class="b-ref">35</span>time complexity of<span> this step </span>is linear in terms of the number of data</a> points. Also, calculation of distance for each data point does not depend on any other data point and so processing for all the data points can continue in parallel. We will pay special attention to the arrangement of data points and centroids inside GPU memory. Also, because of the limited on-chip memory available in a GPU core we need to optimize our implementation such that loading of data points inside on-chip memory is in parallel with distance calculation, so that the cores are never idle. We will start with an implementation for the special case where the input data points are low-dimensional. We will look at the various possible storage arrange- ments and their effect on the processing efficiency. On the basis of our observations for the special case of low-dimensional data points, we will finally create a generic implementation which can efficiently parallelize assignment of data points of any dimension and is fully scalable. We will continue to use the naming convention introduced in Section 2.3.1. For all remaining chapters same naming convention will be used. 21 4.1 Special Case: Low-dimensional Input We will consider the case where the dimension d of input data is small enough to load one complete data point inside the on-chip registers available to a thread. Since, the <a href="javascript:openDSC(40447135, 37, '11298');" onmouseover="doRollover(31);" onmouseout="undoRollover(31);" id="11298" name="31" style="color:#00cc99" class="#00cc99"><span class="b-ref">31</span>number of registers available per thread</a> are limited (64 and 128 in C2070 and C1060 respectively), we will only be considering inputs with value of d up to 22. Each thread will be assigned a data point. It will calculate the <a href="javascript:openDSC(192892550, 1, '15151');" onmouseover="doRollover(61);" onmouseout="undoRollover(61);" id="15151" name="61" style="color:#cc0066" class="#cc0066"><span class="b-ref">61</span>distance of the data-point from all the<span> k </span>centroids. The<span> index of </span>the</a> nearest centroid will be stored in an array of length n and will be the final output. 4.1.1 Storage of data points The data points are stored in device memory as it has the maximum capacity. Also, once copied into the device memory the data points will never need to be re-arranged so the cost of copying data from host memory to device memory is one time. While loading the data points from device memory, threads belonging to the same warp load the same dimension of successive data points. To ensure that each load by a warp completes in a single transaction the data points are arranged as [d][n] i.e. first dimension of all data points, followed by second dimension of all data points and so on. Still, if value of n is not a multiple of transaction-width of device memory, a single read by warp might require two transactions. To avoid this we use cudaM allocP itch function to allocate memory for data points with padding, ensuring that first value for each dimension starts at transaction boundary. cudaM emcpy2D is used to copy the data from host into this padded memory. 4.1.2 Loading of data points Since a data-point can be completely loaded inside a thread, all the threads load their data points only once at the beginning of the kernel. While declaring the register array inside a thread we can’t use a variable d for specifying array length. So instead we create a kernel template with dimension d as template variable. At the time of invocation of kernel, we specify the value d as a constant. //Create the kernel template. template &lt;int d&gt; global void findNearest (int n, float ∗datapoint, int K, float ∗membership) { float point[d]; // Get the index of the data point to be processed int index = blockIndx.x ∗ blockDim.x + threadIdx.x; // Load the complete data point # pragma unroll for (int dim=0; dim&lt;d; dim++) { point[dim] = datapoint[n∗dim + index]; } //Calculate distance from each centroid one by one. for ( int k=0; k&lt;K; k++) { //Get distance from current centroid dist = getDist(k); //If distance is less than minimum distance then update it. if (dist &lt; min) { nearest = k; min = dist; } } //Store index of centroid with minimum distance. membership[index] = nearest; } // kernel template invocation. switch (d) { case 1: findNearest&lt;1&gt;&lt;&lt;grid size , block size&gt;&gt; (..); break; case 2: findNearest&lt;2&gt;&lt;&lt;grid size , block size&gt;&gt; (..) ; break; . . case 22: findNearest&lt;22&gt;&lt;&lt;grid size , block size&gt;&gt; (..) ; break; } 4.1.3 Loading of centroids All the threads need to access the same K centroids. This gives an excellent oppor- tunity for reusing the centroid values loaded from device memory. This can be done by loading the centroids in shared memory. Also, all the threads inside a warp ac- cess the same dimension of a single centroid. Due to this broadcast access, constant memory can also be used for storing the centroid. We compare both the approaches. Centroid in shared memory We consider the optimum case where value K and d are such that all the centroids can be accommodated in the shared memory at once. All the threads after loading their data points, load all the centroids in shared memory. Threads in the same block wait till all the threads finish loading the centroids to ensure that all centroid values have been loaded into shared memory. Once centroids are loaded no more device memory accesses are required and each thread computes the distance from all the centroids by using data point present in its on-chip registers and centroids present in shared memory. Finally, the index of the closest centroid is stored in the membership array in a coalesced manner. Centroid in constant memory In the case of access from constant memory, once the data point has been loaded by a thread, it can directly start accessing the centroid values for distance computation. Also, since each thread first computes distance from one centroid before moving onto the next centroid, we store centroids as [K][d] to ensure spatial locality inside constant memory cache. Centroid in device memory For the case of Fermi, data in device memory is also cached (until written to) in on-chip L1 cache. So for C2070, we also try accessing centroid directly from device memory instead of loading it into shared memory. In this case also, after loading of data points each thread can directly start computing the distance from centroids. We set the size of the L1 cache to 48KB, so that more space is available for caching the centroids. Analysis Tables 4.1 and 4.2 show the comparison of runtime on C1060 and C2070 for the different approaches discussed above. Second last column in each table shows the time taken to execute the kernel when the centroids are accessed from shared memory but the centroid values are not loaded from device memory. On comparing the second last and third last columns we can conclude that the time taken in loading of centroids in shared memory from device memory does not have much impact on the runtime. For C1060, constant memory gives much better performance than shared mem- ory. It also outperforms the case when there is no loading delay in shared memory. This clearly shows that the accesses from the constant cache are much faster than those from the shared memory. Our benchmarking experiments also showed that throughput achieved from shared memory accesses is three-fourth of the throughput achievable by register accesses. For the last row in Table 4.1, shared memory without any load latency achieves 345 GFlop/s whereas constant memory achieves 418 GFlop/s. With a single in- struction executing every cycle, C1060 can achieve 311 GFlop/s for single precision n k d Centroid in shared (ms) Centroid in shared (no loading) (ms) Centroid in constant (ms) 1000000 100 2 144.949 136.497 101.8 1000000 100 4 226.485 214.307 189.069 1000000 100 6 310.873 295.749 256.848 1000000 100 8 395.369 377.717 324.207 1000000 100 10 478.628 460.491 390.703 1000000 100 12 563.822 542.453 457.283 1000000 100 14 649.383 625.637 522.894 1000000 100 16 733.757 707.335 588.915 1000000 100 18 819.075 790.253 654.948 1000000 100 20 902.335 872.237 721.292 1000000 100 22 987.537 954.896 788.082 Table 4.1: Comparison of runtime for 50 iterations of label assignment on C1060 for low-dimensional data with different access locations for centroid. floating point operations. During distance calculation, the typical operations are as follows. distance += (point [ i ] − centroid [ i ]) ∗(point [ i ] − centroid [ i ]) ; This can be broken down into one ADD operation to calculate the difference for the ith dimension followed by a M AD operation that squares the difference and adds it into distance variable. Both ADD and M AD operations take one cycle each. So every distance updation takes two cycles and performs three single-precision floating point operations. C1060 also allows us to perform a M U L operation in parallel with a M AD provided the operands are different. To use the parallel M U L operation, the distance calculation can be modified as: temp1 = (point[i] − centroid[i]); temp2 = (point[i+1] − centroid[i+1]); distance += temp1∗tmp1; temp2 ∗= temp2; distance += temp2; // ADD // ADD // MAD+MUL // ADD Here two distance updations are coupled together to use a M U L operation in parallel with M AD operation. But this too takes four cycles for two updations. Hence, maximum possible throughput for distance calculation is 311∗(3/2) i.e. 466 GFlop/s. With constant memory, we are able to achieve almost 89% of this peak throughput. On C2070, the L1 cache used for caching accesses from global memory is not able to perform as well as the cache provided by constant memory. Here also, when the centroids are in shared memory, loading of centroids from device memory causes very small overhead, as can be seen by comparing the second last and the third last columns of Table 4.2. n k d Centroid in global (ms) Centroid in shared (ms) Centroid in shared (no loading) (ms) Centroid in constant (ms) 1000000 100 2 108.5 96.95 93.7 95.462 1000000 100 4 168.3 145.3 142.9 142.994 1000000 100 6 227.65 195.2 189.65 190.869 1000000 100 8 286.3 244.55 239.6 238.95 1000000 100 10 354.95 293 287.5 288.195 1000000 100 12 418.1 343.15 335.5 333.514 1000000 100 14 479.1 392.5 385.1 386.501 1000000 100 16 541.95 441.45 431.15 436.69 1000000 100 18 605.6 490.55 483.3 489.173 1000000 100 20 669.5 540.9 530.8 532.128 1000000 100 22 731.5 591.15 579.7 583.321 Table 4.2: Comparison of runtime for 50 iterations of label assignment on C2070 for low-dimensional data with different access locations for centroid. Constant memory again performs better than shared memory, but the advantage is much less in comparison to C1060. Three single precision floating point operations every two cycles can give a maximum throughput of around 760 GFlop/s on C2070. We are able to achieve around 75% of it. One major issue with achieving high throughput on Fermi based GPUs is that due to the presence of two warp schedulers higher number of warps are needed to keep both schedulers busy and hide the latency in comparison to C1060. While we use 256 threads per block for constant memory kernel, we need as many as 768 threads per block to achieve the maximum throughput for shared memory. Since with constant memory we can hide latency with less number of threads, we use constant memory for our generic implementation. 4.2 Generic Implementation Based on our observations from the last section we create a generic implementation for label assignment. Once again, each thread is going to be responsible for only one data point. So for the same reasons as mentioned in Section 4.1.1, data points are stored as [d][n] with padding in device memory. Keeping centroids in constant memory ensures that each thread works completely independent of other threads. Also, on-chip constant memory cache is separate from the L1 cache present on Fermi. So we will also avoid thrashing in the L1 cache. Finally, as observed in last section, less number of threads are needed as compared to shared memory for achieving high throughput with constant memory reads. This gives us the freedom to use more registers per thread to hide latencies of global memory reads. 4.2.1 Loading of data points Unlike the low-dimensional case, we cannot assume that every time we will have enough registers to read a data point completely. As a result, a thread would only be able to store some di dimensions of its data point at any given point. Also, now there won’t be a single one-time load of data points from device memory. Since we will keep on loading dimensions of the data points and calculating the distance simultaneously, we need to ensure that for each dimension loaded there are enough number of compute instructions so as to cover the latency for read of the next dimension. So we load only single dimension at a time and update the distance from maximum number of centroids while the next dimension loads from the device memory. 4.2.2 Loading of centroids While previously each thread calculated the distance from one centroid before load- ing the next centroid, here since the thread has only one dimension of its data point loaded in its registers, it loads the same dimension for some k centroids and updates its distance with them. Although we still have broadcast access of centroids, the first k calls are made to load the same dimension of successive k centroids. So we store the centroids in constant memory as [d][K] to achieve higher spatial locality. The value k depends on the latency of global reads. We keep it as the template variable this time so that we can specify it as the length for our distance array. //Generic kernel template. template &lt;int k&gt; global void findNearest (int n, float ∗datapoint , int K, ..){ float point; float dist[k]; // Get the index of the data point to be processed int index = blockIndx.x ∗ blockDim.x + threadIdx.x; // Calculate distance from centroids in groups of k. for (int cent=0; cent&lt;K; cent+=k) { //Calculate distance from k centroids. for (int dim=0; dim&lt;d; dim++) { //Load dim dimension of point point = datapoint[n∗dim + index]; //Update distance from current k centroids updateDist(dim,k,point ,dist); } //Update minimum distance and nearest centroid. } //Store index of centroid with minimum distance membership[index] = nearest; } 4.2.3 Analysis The major overhead in the generic implementation is the continuous loading of all the dimensions of the data point from device memory while calculating its distance from all the centroids. For every dimension read by a thread, it performs k distance updations. By increasing the value of template variable k, we can increase the number of compute operations being performed for every read, which should help in hiding the latency of the read from device memory. But for every increase in value of k, the kernel requires another register for storing distance from the centroid. Thus, we can only hide the latency up to an extent. k Data point read from (ms) device Data point not read from device (ms) Extra time for reading data point (%) 1 40.786 19.612 107.96 2 20.528 12.855 59.69 4 10.986 9.513 15.48 8 8.552 7.788 9.81 12 8.109 7.46 8.70 16 7.295 6.909 5.59 Table 4.3: Change in device memory read overhead with increase in distance upda- tions per read on C1060 for n=819200, d=34, K=32 in a single kernel iteration of generic findCluster. Table 4.3 compares the time spent in assigning labels when data points are read from device memory and when they are not. When for each read dimension only one distance updation was done (k = 1), read from device memory took 100% extra time. On the other hand, as we keep on increasing the value of k, extra time spent in reading data points reduces, reaching below 10% after k = 8. Thus by keeping the value of k as 8 or higher, we can ensure that most of the time spent in extra device memory reads for repeated loads of the dimensions of the data points can be masked by parallel compute operations performed during updation of distance. 4.2.4 Scalability Above implementation does not assume any of the input parameters to fall within any range. The data points are processed by each thread independent of all other threads making it scalable to any value of n. If value of n is so high that all the data points cannot be accommodated in device memory at once, we can run the kernel multiple times with device memory containing the data points to be processed in the current invocation. The centroids are processed by each thread in batches of size k at a time, making it scalable for any large value of k. If the centroids are too many to accommodate in constant memory at once, we can run the kernel multiple times and calculate distance from all the centroids. The number of computations and loads from device and constant memory woulds still be the same. Final input parameter is the dimensionality of input data, d. Each thread cal- culates distance of the data point one dimension at a time. As a result, it can work for large values of dimension d also. Chapter 5 Compute New Centroids In the last chapter, the data points were assigned labels and their labels were stored in a membership array inside device memory. The index of the centroid nearest to ith data point is stored at membership[i]. Now we create an efficient implementation to compute the new values of cluster centers by taking mean of co-ordinates of all the data points that belong to them. This process is not compute-intensive. For every data point, we check the value of membership from device memory and then add up all its co-ordinates into the sum of co-ordinates of the cluster it belongs to. The operation is shown below for co-ordinate d of point i. sum [ membership [ i ] ] [ d ] += point [ i ] [ d ] ; Since there are no compute operations to hide the latency of data reads from device memory, we try to ensure that all the memory reads are fully coalesced. Also, to avoid repeated writes to device memory (for updation of sum by each and every data point), we would like to go through all the data points, keep reducing the co- ordinate sum inside on-chip memory and then finally store it inside device memory once all the points have been processed. We create an intra-block reduction kernel to achieve this. Reduction of co-ordinates for every cluster can be performed in parallel to other clusters. Each CUDA block reduces the co-ordinates for a particular cluster, k. Also, 32 the total number of blocks launched are a multiple of total number of clusters K. Data points are divided equally among all the blocks reducing for the same cluster. After all the blocks have finished execution, for every cluster k, we reduce the sums of co-ordinates of all the blocks that were invoked for it to get the final reduced sum for k. The count of members is also reduced along with the co-ordinates inside the blocks and so we finally get the new centroid by taking mean of the reduced sum of each dimension. This step is performed in a separate inter-block reduction kernel. 5.1 Intra-block Reduction Each block knows the cluster k it is reducing for. Also, it knows the range of data points it has to reduce. For each data-point assigned to k, it adds the co-ordinates in its on-chip memory and increments count. Once all the points have been processed, the reduced sums and count are copied into device memory. global void intraBlockReduction (int K, int ∗membership, float ∗datapoint) { int clusterIndex = blockIdx.x % K; for ( /∗ every data point i to be checked ∗/ ) { // check the membership isMember = checkMembership(clusterIndex , membership[i]); if ( isMember == true ) { // Add co−ordinates in on−chip memory addDimensions(datapoint[i], sum); count++; } } // All the points have been processed. storeReducedValues(sum, count); } 5.1.1 Checking membership For coalesced accesses from membership array, successive threads read successive values from the device memory. After one such read, a warp has the membership values for 32 data points; see Figure 5.1a. (a) Load membership values (b) Store isM ember (c) Find member (d) Add co-ordinates Figure 5.1: Illustration of intra-block reduction performed by a warp w on data points i to i + 31. (a) Threads t1 to t32 load the membership values for points i to i + 31. (b) Each thread stores boolean isM ember for corresponding data point into shared memory. (c) All 32 threads check value of isM ember for each point till they find point i + p with value 1. (d) Successive co-ordinates of point i + p are added by successive threads into their private arrays. 5.1.2 Reduce member co-ordinates This is the most crucial step as it involves maximum device memory reads. To ensure that co-ordinates of every member data point are read from device memory in a coalesced manner, separate reduction is performed by each warp inside the block. Data points to be processed by each block are partitioned equally among all the warps. Each warp processes its assigned data points without any dependence on threads from other warps as shown in Figure 5.1. When all the points have been processed by every warp, they synchronize and the first warp reduces the sum and count values of all the warps. Successive threads in a warp store successive dimensions of the reduced sum. Since the number of dimensions d can be greater than 32, each thread has a register array of length d/32 to store reduced sum, where value at ith index, denotes the value of (32 ∗ i + threadIdx.x) dimension of the reduced sum; see Figure 5.1d. For every member data point, successive threads read and add the point’s re- spective dimensions inside their private arrays. This requires every thread in the warp to know which of the 32 membership indices were equal to k. Each thread stores value 0 or 1 inside a private register, isMember, to denote whether the the data point it checked is a member or not. On C1060, value of isMember is stored inside shared memory to communicate it with all the threads in the parent warp; see Figures 5.1b and 5.1c. On Fermi based C2070, we use ballot function to communicate the membership of data points within a warp without going through shared memory. Each thread invokes ballot with argument isMember. u i n t members = b a l l o t ( isMember ) ; ballot evaluates isM ember <a href="javascript:openDSC(2426938250, 43, '3499');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="3499" name="4" style="color:brown" class="brown"><span class="b-ref">4</span>for all threads of the warp and returns</a> an integer members whose N th bit is set <a href="javascript:openDSC(2426938250, 43, '3500');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="3500" name="4" style="color:brown" class="brown"><span class="b-ref">4</span>if and only if<span> isM ember </span>evaluates to non-zero for</a> the N th thread of the warp. We find the non-zero bits inside members by using f f s function. f f s <a href="javascript:openDSC(2426938250, 43, '3511');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="3511" name="4" style="color:brown" class="brown"><span class="b-ref">4</span>returns the position of the first (least significant) bit set<span> to 1 </span>in<span> members, where </span>the least significant bit<span> position </span>is</a> 1. Since, ballot is only supported by devices of compute capability 2.x we could not use it on C1060. while(members!=0) { // Find the position of first ( least significant ) bit set to 1 int i = ffs (members)−1; addDimensions(datapoint [ i ] ,sum); count++; // Clear the bit members = ((members &gt;&gt; ( i+1))&lt;&lt;(i +1)); } As shown by Figure 5.1d, successive threads need to access successive <a href="javascript:openDSC(37229747, 917, '11754');" onmouseover="doRollover(58);" onmouseout="undoRollover(58);" id="11754" name="58" style="color:#cc9900" class="#cc9900"><span class="b-ref">58</span>dimensions of the same data point.<span> So </span>the data<span> points should be </span>stored as<span> [n </span>][d]</a> inside device memory. But while assigning the clusters in Section 4.1.1, they were required to be stored as [d][n]. To have data reads coalesced for both the cases we keep two copies of data points, one as [n][d] and one as [d][n] inside device memory. 5.1.3 Store reduced values The final reduced values of sum and count are stored inside device memory. Each block stores its count in an array in device memory at index blockIdx.x. The values of the reduced sum are stored as [K][b], where b denotes the memory required for storing the reduced values of sum for all the blocks assigned to the same cluster. For each assigned cluster, every block stores all the dimensions of its reduced sum at continuous memory locations. This helps coalesce the memory writes by each block. 5.2 Inter-block Reduction After the completion of intra-block reduction, a separate kernel is invoked to reduce the values of sum and count that were stored for each cluster in Section 5.1.3. One kernel block is created for each cluster and so the <a href="javascript:openDSC(2426938250, 43, '3493');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="3493" name="4" style="color:brown" class="brown"><span class="b-ref">4</span>total number of<span> blocks </span>is equal to the number of<span> clusters. Each kernel </span>block<span> reduces </span>the</a> values stored by all the blocks <a href="javascript:openDSC(37310718, 917, '16152');" onmouseover="doRollover(35);" onmouseout="undoRollover(35);" id="16152" name="35" style="color:#9c6331" class="#9c6331"><span class="b-ref">35</span>in Section 5.1.<span> 3 </span>for the</a> cluster k assigned to it. After reducing the sum and count values for cluster k, it finds the mean for every dimension. These means are the final co-ordinates of the centroid. Finally, each block stores the obtained co-ordinates of its centroid k, inside device memory. Chapter 6 Experimental Results 6.1 Experimental Setup The CUDA kernels are executed on NVIDIA’s C1060 and C2070 GPUs. The <a href="javascript:openDSC(42211312, 37, '11942');" onmouseover="doRollover(11);" onmouseout="undoRollover(11);" id="11942" name="11" style="color:#ff0063" class="#ff0063"><span class="b-ref">11</span>core and memory clock frequencies of<span> C1060 </span>are 1.<span> 3 </span>GHz and</a> 800 MHz. It contains 240 cores arranged in 30 streaming multiprocessors. C2070 is Fermi-based and has <a href="javascript:openDSC(42211312, 37, '11945');" onmouseover="doRollover(11);" onmouseout="undoRollover(11);" id="11945" name="11" style="color:#ff0063" class="#ff0063"><span class="b-ref">11</span>core and memory clock frequencies of</a><a href="javascript:openDSC(42211312, 37, '11946');" onmouseover="doRollover(11);" onmouseout="undoRollover(11);" id="11946" name="11" style="color:#ff0063" class="#ff0063"><span class="b-ref">11</span>1.15 GHz and 1.49 GHz.</a> It has 448 cores arranged in fourteen streaming multiprocessors. For our CPU executions, we use a quad-processor SMP, Xeon server. The four processors are <a href="javascript:openDSC(42211312, 37, '11947');" onmouseover="doRollover(11);" onmouseout="undoRollover(11);" id="11947" name="11" style="color:#ff0063" class="#ff0063"><span class="b-ref">11</span>hex-core, Intel X7460<span> CPUs </span>running at 2.</a> 66GHz. 6.2 Comparison with CPU We compare our GPU implementation with our modified NU-Minebench implemen- tation (mentioned in Section 2.4.2) running on our 24-core Xeon server. We use two real world datasets as input for our comparisons. Our first input dataset is KDD Cup 1999 [15]. It contains 4,898,431 data points, each having 41 attributes. Tables 6.1 and 6.2 show the speedup obtained with change in number of data-points and clusters respectively. Next we perform comparison for Covertype Data Set [7]. It contains 581,012 data points, each having 54 attributes. Tables 6.3 and 6.4 show the speedup obtained 38 CHAPTER 6. EXPERIMENTAL RESULTS n Execution time CPU (ms) Execution time C1060 (ms) Speedup over CPU Execution time C2070 (ms) Speedup over CPU 1000000 9865 2596 3.80 1425 6.92 1500000 14672 3881 3.78 2117 6.93 2000000 19605 5171 3.79 2743 7.15 2500000 23828 6456 3.69 3414 6.98 3000000 29021 7746 3.75 4078 7.12 3500000 34075 9027 3.77 4688 7.27 4000000 38831 10362 3.75 5380 7.22 4500000 43605 11595 3.76 6036 7.22 Table 6.1: KDD Cup 1999 Data Set: Execution times for K-means on CPU and GPU. K = 64, d = 41, number of iterations= 50 K Execution time CPU (ms) Execution time C1060 (ms) Speedup over CPU Execution time C2070 (ms) Speedup over CPU 32 10782 2783 3.87 1578 6.83 64 19605 5171 3.79 2743 7.15 96 28754 7586 3.79 3907 7.36 128 37055 10158 3.65 5061 7.32 160 46762 12396 3.77 6392 7.32 Table 6.2: KDD Cup 1999 Data Set: Execution times for K-means on CPU and GPU. n = 2000000, d = 41, number of iterations= 50 with change in number of data-points and clusters respectively. We note that although C1060 has 240 cores, the frequency of CPU cores is twice that of GPU cores. For the case of Fermi it is in fact 2.5x times. Also, during data load intensive reduction operation, CPU has larger caches: 36 MB L2 and 64 MB L3. In comparison, C1060 does not have any L2 cache causing much larger latency for load operations during reduction. On Fermi-based C2070 there is a 768 KB L2 cache. It enables C2070 to achieve better performance during reduction in comparison with C1060. Also, the availabil- ity of ballot function ensures that the threads in a warp do not have to use shared memory for checking the membership of data points during reduction. This is why C2070 is consistently able to achieve a better speedup as compared to C2070. CHAPTER 6. EXPERIMENTAL RESULTS n Execution time CPU (ms) Execution time C1060 (ms) Speedup over CPU Execution time C2070 (ms) Speedup over CPU 100000 1290 303.4 4.25 168.5 7.66 200000 2835 603.35 4.70 332.1 8.54 300000 3227 889.2 3.63 494.15 6.53 400000 4371 1186.9 3.68 652.6 6.70 500000 5325 1472.5 3.62 817.8 6.51 580000 6298 1710.4 3.68 954 6.60 Table 6.3: Covertype Data Set: Execution times for K-means on CPU and GPU. K = 64, d = 54, number of iterations= 50. K Execution time CPU (ms) Execution time C1060 (ms) Speedup over CPU Execution time C2070 (ms) Speedup over CPU 32 3145 761.15 4.13 476.4 6.60 64 5325 1472.35 3.62 778.15 6.84 96 7835 2115.2 3.70 1118.6 7.00 128 10343 2886.55 3.58 1484.7 6.97 160 12162 3473.4 3.50 1838.85 6.61 192 15366 4200 3.66 2253.06 6.82 Table 6.4: Covertype Data Set: Execution times for K-means on CPU and GPU. n = 500000, d = 54, number of iterations= 50. 6.3 Comparison with Published Results Figure 6.1 shows a comparison between our implementation and those by Li et al [17], University of Virginia [4] and GPUMiner [9]. The execution times are taken from [17] for a sample dataset provided by KDD Cup 1999 [15]. The sample contains 51,200 data points, each having 34 attributes. Our implementation is able to perform better than the published results in Li et al [17]. Table 6.5 shows a comparison of execution time of our K-means implementation with timings reported by Li et al [17]. Value for n is 51,200, K is 32 and the execution time is taken for 100 iteration of K-means. Our K-means consistently performs better than [17]. Even when d = 160, we are able to achieve over 1.5x speedup. CHAPTER 6. EXPERIMENTAL RESULTS Figure 6.1: Comparison of execution time of our implementation of K-means with Li et al [17], University of Virginia [4] and GPUMiner [9] for 100 iterations on KDD Cup 1999 Dataset [15], with K = 32, d = 34, n = 51200 d Execution time Li et al [17] (ms) Execution time our K-means (ms) 32 328 129 64 403 185.5 96 447 224.4 128 475 273.3 160 523 331.2 Table 6.5: Comparison of execution times of our K-means implementation with timings in Li et al [17]. K = 32, n = 51200, number of iterations= 100. Chapter 7 Conclusions and Future Work The main aim of this study was to achieve high throughput for K-means algorithm on NVIDIA’a GPUs. We were able to achieve around 89% of the peak throughput on Tesla C1060 GPU. On Fermi-based Tesla C2070 GPU we were able to achieve 75% of the peak throughput for K-means operation. Also, we have been able to achieve better efficiency than the currently available GPU implementations for basic K-means algorithm. Our implementation is scalable and does not have any limiting conditions on the input sets it can process. One immediate extension of this would be to use the generic implementation across multiple GPUs. This way we could further reduce the execution time, especially during label assignment. There have been many extensions <a href="javascript:openDSC(41274837, 37, '13413');" onmouseover="doRollover(30);" onmouseout="undoRollover(30);" id="13413" name="30" style="color:#330099" class="#330099"><span class="b-ref">30</span>of the<span> original </span>K-means algorithm. In</a> our study, <a href="javascript:openDSC(41274837, 37, '13411');" onmouseover="doRollover(30);" onmouseout="undoRollover(30);" id="13411" name="30" style="color:#330099" class="#330099"><span class="b-ref">30</span>we have implemented the<span> basic </span>K-means</a> algorithm. It would be interesting to implement extensions of K-means algorithm using our generic implementation as the base. There are extensions which decrease the number of reduction operations required for computing new centroids. Such extensions might be able to achieve even higher efficiency on GPUs. 42 Bibliography [1] <a href="javascript:openDSC(274072414, 1, '10681');" onmouseover="doRollover(28);" onmouseout="undoRollover(28);" id="10681" name="28" style="color:#009cff" class="#009cff"><span class="b-ref">28</span>G.H. Ball and D.J. Hall. Isodata, a novel method of data analysis and pattern<span> classification. </span>Technical report, DTIC Document, 1965.</a> [2] <a href="javascript:openDSC(182247953, 943, '6563');" onmouseover="doRollover(44);" onmouseout="undoRollover(44);" id="6563" name="44" style="color:green" class="green"><span class="b-ref">44</span>A. Baraldi and E. Alpaydin. Constructive feedforward art clustering networks. ii.<span> Neural Networks, </span>IEEE Transactions on,</a> 13(3):662 –677, may 2002. [3] <a href="javascript:openDSC(40156349, 37, '11100');" onmouseover="doRollover(37);" onmouseout="undoRollover(37);" id="11100" name="37" style="color:#cc9900" class="#cc9900"><span class="b-ref">37</span>F. Cao, A. Tung, and A. Zhou. Scalable clustering using graphics processors.<span> Advances </span>in Web-Age Information Management,</a> pages 372–384, 2006. [4] S. <a href="javascript:openDSC(2826883820, 304, '74');" onmouseover="doRollover(10);" onmouseout="undoRollover(10);" id="74" name="10" style="color:#00cc99" class="#00cc99"><span class="b-ref">10</span>Che, M. Boyer, J. Meng, D. Tarjan, J.W. Sheaffer, and K. Skadron. A performance study of general-purpose applications on graphics processors using cuda.<span> J. </span>Parallel<span> Distrib. Comput., </span>68(10):1370–1380,<span> October </span>2008.<span> [5] S. </span>Che, J.<span> Meng, </span>J.W. Sheaffer,<span> and </span>K. Skadron.</a><a href="javascript:openDSC(3214381784, 304, '897');" onmouseover="doRollover(26);" onmouseout="undoRollover(26);" id="897" name="26" style="color:#ff6600" class="#ff6600"><span class="b-ref">26</span>A performance study of general purpose applications on graphics processors. In<span> The </span>First Workshop on General Purpose Processing on Graphics Processing Units, 2007.</a><a href="javascript:openDSC(1234417643, 304, '4054');" onmouseover="doRollover(25);" onmouseout="undoRollover(25);" id="4054" name="25" style="color:brown" class="brown"><span class="b-ref">25</span>[6] V.<span> S. </span>Cherkassky and F. Mulier. Learning from Data: Concepts, Theory, and Methods. John Wiley &amp; Sons, Inc., New York, NY, USA,<span> 1st edition, </span>1998. [7]</a> Covertype <a href="javascript:openDSC(334853088, 772, '881');" onmouseover="doRollover(64);" onmouseout="undoRollover(64);" id="881" name="64" style="color:red" class="red"><span class="b-ref">64</span>Data Set. http://archive.ics.uci.edu/ml/datasets/<span> Covertype. </span>[Online].</a><a href="javascript:openDSC(1193903590, 304, '2077');" onmouseover="doRollover(13);" onmouseout="undoRollover(13);" id="2077" name="13" style="color:#9966ff" class="#9966ff"><span class="b-ref">13</span>[8] P. Drineas, A. Frieze, R. Kannan, S. Vempala, and V. Vinay. Clustering in large graphs and matrices. In Proceedings of the tenth annual ACM-SIAM symposium on Discrete algorithms, pages 291–299.<span> Citeseer, </span>1999. [9]</a><a href="javascript:openDSC(40137193, 37, '9619');" onmouseover="doRollover(6);" onmouseout="undoRollover(6);" id="9619" name="6" style="color:#630000" class="#630000"><span class="b-ref">6</span>W. Fang, K.K. Lau, M. Lu, X. Xiao, C.K. Lam, P.Y. Yang, B. He, Q. Luo, P.V. Sander, and K. Yang. Parallel data mining on graphics processors. Hong Kong University of Science and Technology, Tech. Rep. HKUST-CS08-07,</a> 2008. [10] <a href="javascript:openDSC(42351136, 37, '11681');" onmouseover="doRollover(65);" onmouseout="undoRollover(65);" id="11681" name="65" style="color:green" class="green"><span class="b-ref">65</span>R. Farber. CUDA application design and development. Morgan Kaufmann, 2011.</a> [11] <a href="javascript:openDSC(37342137, 917, '16711');" onmouseover="doRollover(59);" onmouseout="undoRollover(59);" id="16711" name="59" style="color:#63009c" class="#63009c"><span class="b-ref">59</span>P.N. Glaskowsky. Nvidias fermi: the first complete gpu computing architecture.</a> NVIDIA Corporation, September, <a href="javascript:openDSC(11490875, 772, '5442');" onmouseover="doRollover(34);" onmouseout="undoRollover(34);" id="5442" name="34" style="color:#9966ff" class="#9966ff"><span class="b-ref">34</span>2009. [12] J.A. Hartigan and M.A. Wong. Algorithm as 136: A k-means clustering<span> algo- rithm. </span>Applied statistics,</a> pages 100–108, 1979. [13] <a href="javascript:openDSC(30748419, 37, '18706');" onmouseover="doRollover(22);" onmouseout="undoRollover(22);" id="18706" name="22" style="color:red" class="red"><span class="b-ref">22</span>A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM<span> Comput. Surv., </span>31(3):264–323, September 1999.<span> 43 BIBLIOGRAPHY [14] </span>A.K. Jain.</a><a href="javascript:openDSC(2139013719, 1274, '2663');" onmouseover="doRollover(41);" onmouseout="undoRollover(41);" id="2663" name="41" style="color:#33cc99" class="#33cc99"><span class="b-ref">41</span>Data clustering: 50 years beyond k-means. Pattern Recognition Letters, 31(8):651–666, 2010.</a> [15] KDD Cup 1999 Data Data Set. <a href="javascript:openDSC(41257482, 37, '12286');" onmouseover="doRollover(53);" onmouseout="undoRollover(53);" id="12286" name="53" style="color:#ff0063" class="#ff0063"><span class="b-ref">53</span>http://archive.ics.uci.edu/ml/datasets/ KDD+Cup+1999+Data.<span> [Online]. [16] </span>D.</a><a href="javascript:openDSC(188342778, 1, '18924');" onmouseover="doRollover(23);" onmouseout="undoRollover(23);" id="18924" name="23" style="color:green" class="green"><span class="b-ref">23</span>B. Kirk and<span> W.H. </span>Wen-mei. Programming Massively Parallel Processors: A Hands-on Approach. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1st edition, 2010.</a> [17] <a href="javascript:openDSC(40470157, 37, '9665');" onmouseover="doRollover(8);" onmouseout="undoRollover(8);" id="9665" name="8" style="color:#31ff00" class="#31ff00"><span class="b-ref">8</span>Y. Li, K. Zhao, X. Chu, and J. Liu. Speeding up k-means algorithm by gpus. In Computer and Information Technology (CIT), 2010 IEEE 10th International Conference on,<span> pages </span>115–122.</a> IEEE, 2010. [18] S. <a href="javascript:openDSC(37864412, 37, '18711');" onmouseover="doRollover(39);" onmouseout="undoRollover(39);" id="18711" name="39" style="color:#cc6600" class="#cc6600"><span class="b-ref">39</span>Lloyd. Least squares quantization in pcm. Information Theory, IEEE<span> Trans- actions </span>on, 28(2):129 – 137, mar 1982.</a> [19] <a href="javascript:openDSC(827382391, 772, '189');" onmouseover="doRollover(20);" onmouseout="undoRollover(20);" id="189" name="20" style="color:#33cc99" class="#33cc99"><span class="b-ref">20</span>W. Ma and G. Agrawal. A translation system for enabling data mining<span> appli- cations </span>on gpus. In Proceedings of the 23rd international conference on<span> Super- computing, </span>pages 400–409.</a> ACM, 2009. [20] <a href="javascript:openDSC(195145687, 1, '14202');" onmouseover="doRollover(16);" onmouseout="undoRollover(16);" id="14202" name="16" style="color:#cc9900" class="#cc9900"><span class="b-ref">16</span>J. MacQueen et al. Some methods for classification and analysis of multivariate<span> observations. </span>In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, volume 1, page 14. California, USA, 1967.<span> [21] J. Nickolls </span>and<span> W </span>.J.</a><a href="javascript:openDSC(40447135, 37, '11305');" onmouseover="doRollover(31);" onmouseout="undoRollover(31);" id="11305" name="31" style="color:#00cc99" class="#00cc99"><span class="b-ref">31</span>Dally. The gpu computing era. Micro, IEEE, 30(2):56–69, 2010.<span> [22] </span>CUDA</a> Toolkit Documentation. http://docs.nvidia.com/cuda/index.html. [Online]. [23] NVIDIAs <a href="javascript:openDSC(41025735, 37, '11139');" onmouseover="doRollover(27);" onmouseout="undoRollover(27);" id="11139" name="27" style="color:#630000" class="#630000"><span class="b-ref">27</span>Next Generation CUDA Compute Architecture: Fermi. http://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_ Fermi_Compute_Architecture_Whitepaper.pdf.<span> [Online]. [24] C. </span>Nvidia.</a><a href="javascript:openDSC(38304734, 37, '9494');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="9494" name="2" style="color:green" class="green"><span class="b-ref">2</span>Compute unified device architecture programming guide.</a> 2007. [25] OpenMP Specification. http://openmp.org/wp/openmp-specifications/. [Online]. [26] <a href="javascript:openDSC(38304734, 37, '9505');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="9505" name="2" style="color:green" class="green"><span class="b-ref">2</span>J. Pisharath, Y. Liu, W. Liao, A. Choudhary, G. Memik, and J. Parhi. Nu- minebench 2.0. Technical report,<span> Technical Report </span>CUCIS-2005-08-01, Center for Ultra-Scale Computing and Information Security, Northwestern University, 2005.</a> [27] <a href="javascript:openDSC(1755399742, 1274, '7610');" onmouseover="doRollover(42);" onmouseout="undoRollover(42);" id="7610" name="42" style="color:#336699" class="#336699"><span class="b-ref">42</span>Record Linkage Comparison Patterns<span> Data Set. </span>http://archive.ics.uci. edu/ml/datasets/Record+Linkage+Comparison+Patterns.</a> [Online]. [28] L. Rokach and O. Maimon. Clustering methods. <a href="javascript:openDSC(212169360, 772, '5578');" onmouseover="doRollover(36);" onmouseout="undoRollover(36);" id="5578" name="36" style="color:#ce0031" class="#ce0031"><span class="b-ref">36</span>In Oded Maimon and Lior Rokach, editors, The Data Mining and Knowledge Discovery Handbook, pages<span> 321</span><span>–352. </span>Springer, 2005.</a> BIBLIOGRAPHY [29] S.Z. Selim and M.A. Ismail. K-means-type algorithms: a generalized conver- gence theorem and characterization of local optimality. Pattern Analysis and Machine Intelligence, IEEE Transactions on, (1):81–87, 1984. [30] H. Steinhaus. Sur la division des corps matériels en parties. Bull. Acad. Pol. Sci., Cl. III, 4:801–804, 1957. [31] H. Takizawa and H. Kobayashi. Hierarchical parallel processing of large scale data clustering on a pc cluster with gpu co-processing. The Journal of Super- computing, 36(3):219–234, 2006. [32] B. Tryon. Cluster analysis. McGraw-Hill, New York, NY, USA, 1970. [33] MK Wasif and PJ Narayanan. Scalable clustering using multiple gpus. In High Performance Computing (HiPC), 2011 18th International Conference on, pages 1–10. IEEE, 2011. [34] R. Wu, B. Zhang, and M. Hsu. Clustering billions of data points using gpus. In Proceedings of the combined workshops on UnConventional high performance computing workshop plus memory access workshop, pages 1–6. ACM, 2009. [35] R. Xu and D. Wunsch. Clustering. Wiley-IEEE Press, 2009. 2 3 CHAPTER 2. K-MEANS CLUSTERING ALGORITHM 5 CHAPTER 2. K-MEANS CLUSTERING ALGORITHM 6 CHAPTER 2. K-MEANS CLUSTERING ALGORITHM 7 CHAPTER 2. K-MEANS CLUSTERING ALGORITHM 8 CHAPTER 2. K-MEANS CLUSTERING ALGORITHM 9 CHAPTER 2. K-MEANS CLUSTERING ALGORITHM 10 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 12 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 13 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 14 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 15 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 16 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 17 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 18 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 19 CHAPTER 3. CUDA: A GENERAL PURPOSE PARALLEL COMPUTING ARCHITECTURE 20 CHAPTER 4. FINDING NEAREST CENTROID 22 CHAPTER 4. FINDING NEAREST CENTROID 23 CHAPTER 4. FINDING NEAREST CENTROID 24 CHAPTER 4. FINDING NEAREST CENTROID 25 CHAPTER 4. FINDING NEAREST CENTROID 26 CHAPTER 4. FINDING NEAREST CENTROID 27 CHAPTER 4. FINDING NEAREST CENTROID 28 CHAPTER 4. FINDING NEAREST CENTROID 29 CHAPTER 4. FINDING NEAREST CENTROID 30 CHAPTER 4. FINDING NEAREST CENTROID 31 CHAPTER 5. COMPUTE NEW CENTROIDS 33 CHAPTER 5. COMPUTE NEW CENTROIDS 34 CHAPTER 5. COMPUTE NEW CENTROIDS 35 CHAPTER 5. COMPUTE NEW CENTROIDS 36 CHAPTER 5. COMPUTE NEW CENTROIDS 37 39 40 41 44 45 
</div>
</div>
</body>
</html>
